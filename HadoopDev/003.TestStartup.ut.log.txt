C:\Javax64\jdk1.8.0_144\bin\java -ea -DrunningWithNative=true -Dtest.build.dir=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test-dir -Dhadoop.tmp.dir=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test -Dtest.build.data=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test/data -Dtest.build.webapps=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test-classes/webapps -Dtest.cache.data=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test-classes -Dhadoop.log.dir=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/log -Dtest.build.classes=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target/test-classes -Djava.net.preferIPv4Stack=true -Djava.security.krb5.conf=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs/src/test/resources/krb5.conf -Djava.security.egd=file:/dev/urandom -Xmx4096m -XX:MaxPermSize=768m -XX:+HeapDumpOnOutOfMemoryError -Didea.test.cyclic.buffer.size=1048576 "-javaagent:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2017.2.3\lib\idea_rt.jar=55494:C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2017.2.3\bin" -Dfile.encoding=UTF-8 -classpath ... com.intellij.rt.execution.junit.JUnitStarter -ideVersion5 -junit4 org.apache.hadoop.hdfs.server.namenode.TestStartup
2017-10-16 13:05:16,994 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:05:17,291 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(480)) - Test uncompressed image checksum
2017-10-16 13:05:17,291 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(493)) - 
===========================================
Starting empty cluster
2017-10-16 13:05:17,338 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2017-10-16 13:05:17,728 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:17,728 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:17,760 INFO  Configuration.deprecation (Configuration.java:warnOnceIfDeprecated(1173)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2017-10-16 13:05:17,760 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:17,760 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:17,760 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:17,760 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:17
2017-10-16 13:05:17,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:17,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:17,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:17,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:17,775 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:17,775 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:17,775 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:17,775 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:17,775 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:17,791 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:18,291 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:18,291 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:18,291 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:18,291 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:18,291 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:18,307 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:18,307 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:18,307 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:18,307 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:18,307 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:18,307 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:18,307 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:18,307 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:18,307 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:18,307 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:18,307 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:18,307 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:23,172 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-928196769-192.168.232.1-1508173523125
2017-10-16 13:05:23,234 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1 has been successfully formatted.
2017-10-16 13:05:23,297 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2 has been successfully formatted.
2017-10-16 13:05:23,390 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:05:23,390 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:05:23,531 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:05:23,531 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:05:23,640 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:05:23,640 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:05:23,672 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:05:23,719 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:05:23,719 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:05:23,719 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:05:23,750 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:05:23,797 INFO  mortbay.log (Slf4jLog.java:info(67)) - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2017-10-16 13:05:28,325 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:28,325 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:05:28,341 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:28,341 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:05:28,341 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:28,356 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:28,535 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:05:28,535 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:05:28,551 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55499
2017-10-16 13:05:28,551 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:28,691 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55499
2017-10-16 13:05:28,691 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:28,691 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:28,691 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:28,691 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:28,691 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:28,691 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:28
2017-10-16 13:05:28,691 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:28,691 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:28,691 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:28,691 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:28,707 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:28,707 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:28,707 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:28,707 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:28,707 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:28,707 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:28,707 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:28,707 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:28,707 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:28,707 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:28,723 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:28,723 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:28,723 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:28,723 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:28,738 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:28,770 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:28,770 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:05:28,770 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:05:28,770 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:05:28,770 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:28,785 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:28,785 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:28,785 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:05:28,785 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:05:28,785 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:05:28,895 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:05:28,895 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 184 msecs
2017-10-16 13:05:29,113 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:05:29,129 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:05:29,129 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55502
2017-10-16 13:05:29,160 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55502 to access this namenode/service.
2017-10-16 13:05:29,160 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:05:29,160 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:29,160 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:29,160 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:05:29,160 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:05:29,160 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:05:29,160 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:05:29,160 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:05:29,176 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:05:29,176 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:05:29,176 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:05:29,176 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:05:29,176 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:05:29,176 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2017-10-16 13:05:29,191 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:05:29,191 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55502: starting
2017-10-16 13:05:29,191 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55502
2017-10-16 13:05:29,191 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:05:29,191 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:05:31,582 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:31,723 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:31,848 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=Zhibin:supergroup:rwxr-xr-x	proto=rpc
2017-10-16 13:05:31,863 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(505)) - Shutting down cluster #1
2017-10-16 13:05:31,863 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:05:31,863 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:05:31,863 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:05:31,863 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:05:31,863 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 3 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 0 0 
2017-10-16 13:05:31,863 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:05:31,879 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000003
2017-10-16 13:05:31,879 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000003
2017-10-16 13:05:31,895 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:05:31,895 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55502
2017-10-16 13:05:31,895 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55502
2017-10-16 13:05:31,895 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:05:31,895 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:05:31,895 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:05:31,895 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:05:31,910 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:05:32,020 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping NameNode metrics system...
2017-10-16 13:05:32,020 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - NameNode metrics system stopped.
2017-10-16 13:05:32,020 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - NameNode metrics system shutdown complete.
2017-10-16 13:05:32,129 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(518)) - 
===========================================
Starting same cluster after simulated crash
2017-10-16 13:05:32,129 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
2017-10-16 13:05:32,129 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:05:32,129 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:05:32,145 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:05:32,145 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:05:32,145 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:05:32,145 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:05:36,661 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:36,661 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:05:36,661 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55514
2017-10-16 13:05:36,661 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:36,739 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55514
2017-10-16 13:05:36,739 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:36,739 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:36,739 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:36,739 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:36,739 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:36
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:36,754 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:36,754 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:36,754 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:36,754 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:36,754 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:36,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:36,754 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:36,754 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:36,754 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:36,754 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:36,770 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:36,770 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:36,770 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:36,770 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:36,770 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:36,770 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:36,770 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:36,770 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:36,786 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:05:36,786 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:05:36,786 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:36,786 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:36,786 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:36,786 ERROR namenode.FSImage (FSImage.java:loadFSImage(684)) - Failed to load image from FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
java.io.IOException: Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000 is corrupt with MD5 checksum of 71ba4a291f454d2366bf5c46e5724425 but expecting 00000000000000000000000000000000
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:970)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:947)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:746)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:677)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:36,801 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:36,801 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:36,801 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:36,801 ERROR namenode.FSImage (FSImage.java:loadFSImage(684)) - Failed to load image from FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
java.io.IOException: Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000 is corrupt with MD5 checksum of 71ba4a291f454d2366bf5c46e5724425 but expecting 00000000000000000000000000000000
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:970)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:947)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:746)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:677)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:36,817 WARN  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(683)) - Encountered exception loading fsimage
java.io.IOException: Failed to load FSImage file, see error(s) above for more info.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:692)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:36,817 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:05:36,926 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping NameNode metrics system...
2017-10-16 13:05:36,926 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - NameNode metrics system stopped.
2017-10-16 13:05:36,926 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - NameNode metrics system shutdown complete.
2017-10-16 13:05:36,942 ERROR hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(820)) - IOE creating namenodes. Permissions dump:
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
	permissions: ----
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read
	permissions: drwx
path 'K:\HadoopDev': 
	absolute:K:\HadoopDev
	permissions: drwx
path 'K:\': 
	absolute:K:\
	permissions: drwx

java.io.IOException: Failed to load FSImage file, see error(s) above for more info.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:692)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:481)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:36,957 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:05:36,957 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(482)) - Test compressed image checksum
2017-10-16 13:05:36,957 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(493)) - 
===========================================
Starting empty cluster
2017-10-16 13:05:36,957 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:37,004 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:37,004 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:37
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:37,004 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:37,004 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:37,004 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:37,004 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:37,004 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:37,004 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:37,004 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:37,020 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:37,020 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:37,020 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:37,020 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:37,020 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:37,020 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:37,020 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:37,020 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:37,020 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:37,020 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-468844454-192.168.232.1-1508173537020
2017-10-16 13:05:37,098 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1 has been successfully formatted.
2017-10-16 13:05:37,161 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2 has been successfully formatted.
2017-10-16 13:05:37,176 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:05:37,176 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:05:37,176 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:05:37,176 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:05:37,254 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:05:37,270 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:05:37,270 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:05:37,270 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:05:37,270 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:05:37,270 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:05:37,270 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:05:41,800 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:41,800 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:05:41,800 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55517
2017-10-16 13:05:41,800 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:41,878 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55517
2017-10-16 13:05:41,878 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:41,878 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:41,878 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:41,878 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:41,878 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:41,878 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:41
2017-10-16 13:05:41,878 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:41,878 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:41,878 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:41,878 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:41,894 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:41,894 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:41,894 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:41,894 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:41,894 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:41,894 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:41,894 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:41,894 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:41,894 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:41,894 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:41,925 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:41,925 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:41,925 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:41,925 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:41,925 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:41,925 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:41,925 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:41,925 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:41,925 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:41,925 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:41,925 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:41,925 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:41,925 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:41,940 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:41,972 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:41,972 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:05:41,972 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:05:41,972 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:05:41,972 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:41,972 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:41,972 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:41,972 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:05:41,972 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:05:41,972 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:05:42,081 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:05:42,081 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 145 msecs
2017-10-16 13:05:42,081 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:05:42,081 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:05:42,081 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55520
2017-10-16 13:05:42,081 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55520 to access this namenode/service.
2017-10-16 13:05:42,081 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:05:42,081 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:42,081 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:42,081 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:05:42,081 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:05:42,081 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:05:42,081 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:05:42,081 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:05:42,097 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:05:42,097 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:05:42,097 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:05:42,097 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:05:42,097 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:05:42,097 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2017-10-16 13:05:42,097 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:05:42,097 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55520: starting
2017-10-16 13:05:42,097 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55520
2017-10-16 13:05:42,097 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:05:42,097 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:05:42,097 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:42,097 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:42,097 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=Zhibin:supergroup:rwxr-xr-x	proto=rpc
2017-10-16 13:05:42,097 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(505)) - Shutting down cluster #1
2017-10-16 13:05:42,097 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:05:42,097 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:05:42,097 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:05:42,097 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:05:42,097 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:05:42,097 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 3 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 4 SyncTimes(ms): 0 1 
2017-10-16 13:05:42,112 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000003
2017-10-16 13:05:42,112 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000003
2017-10-16 13:05:42,112 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:05:42,112 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55520
2017-10-16 13:05:42,112 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55520
2017-10-16 13:05:42,112 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:05:42,112 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:05:42,112 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:05:42,112 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:05:42,112 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:05:42,222 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping NameNode metrics system...
2017-10-16 13:05:42,222 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - NameNode metrics system stopped.
2017-10-16 13:05:42,222 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - NameNode metrics system shutdown complete.
2017-10-16 13:05:42,300 INFO  namenode.TestStartup (TestStartup.java:testImageChecksum(518)) - 
===========================================
Starting same cluster after simulated crash
2017-10-16 13:05:42,300 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
2017-10-16 13:05:42,300 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:05:42,300 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:05:42,300 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:05:42,300 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:05:42,300 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:05:42,300 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:05:46,822 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:46,822 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:05:46,822 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55528
2017-10-16 13:05:46,822 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:46,884 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55528
2017-10-16 13:05:46,884 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:46,884 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:46,900 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:46,900 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:46
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:46,900 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:46,900 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:46,900 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:46,900 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:46,900 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:46,900 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:46,900 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:46,900 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:46,900 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:46,900 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:46,900 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:46,916 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:46,916 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:46,916 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:46,916 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:46,916 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:46,916 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:46,916 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:46,916 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:46,916 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:46,916 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:46,916 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:46,916 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:46,916 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:46,916 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:46,916 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:05:46,916 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:05:46,916 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:46,916 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:46,916 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:46,916 ERROR namenode.FSImage (FSImage.java:loadFSImage(684)) - Failed to load image from FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
java.io.IOException: Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000 is corrupt with MD5 checksum of a06c9a8c7b42a9ed67825080079502c6 but expecting 00000000000000000000000000000000
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:970)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:947)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:746)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:677)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:483)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:46,931 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:46,931 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:46,931 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:46,931 ERROR namenode.FSImage (FSImage.java:loadFSImage(684)) - Failed to load image from FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
java.io.IOException: Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage_0000000000000000000 is corrupt with MD5 checksum of a06c9a8c7b42a9ed67825080079502c6 but expecting 00000000000000000000000000000000
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:970)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:947)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImageFile(FSImage.java:746)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:677)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:483)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:46,947 WARN  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(683)) - Encountered exception loading fsimage
java.io.IOException: Failed to load FSImage file, see error(s) above for more info.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:692)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:483)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:46,947 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:05:47,056 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping NameNode metrics system...
2017-10-16 13:05:47,056 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - NameNode metrics system stopped.
2017-10-16 13:05:47,056 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - NameNode metrics system shutdown complete.
2017-10-16 13:05:47,056 ERROR hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(820)) - IOE creating namenodes. Permissions dump:
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
	permissions: ----
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project
	permissions: drwx
path 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read': 
	absolute:K:\HadoopDev\hadoop-2.7.3-src-buildX64-read
	permissions: drwx
path 'K:\HadoopDev': 
	absolute:K:\HadoopDev
	permissions: drwx
path 'K:\': 
	absolute:K:\
	permissions: drwx

java.io.IOException: Failed to load FSImage file, see error(s) above for more info.
	at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:692)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:976)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:681)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1493)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1115)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:986)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:524)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testImageChecksum(TestStartup.java:483)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:05:47,072 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:05:47,119 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:05:47,134 INFO  namenode.TestStartup (TestStartup.java:testChkpointStartup1(336)) - --starting testStartup Recovery
2017-10-16 13:05:47,134 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(144)) - --starting mini cluster
2017-10-16 13:05:47,134 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:47,134 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:47,134 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:47
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:47,134 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:47,134 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:47,134 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:47,134 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:47,134 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:47,134 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:47,134 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:47,150 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:47,150 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:47,150 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:47,150 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:47,150 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:47,150 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:47,150 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:47,150 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:47,150 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:47,150 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:47,212 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name has been successfully formatted.
2017-10-16 13:05:47,275 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits has been successfully formatted.
2017-10-16 13:05:47,275 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:05:47,275 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:05:47,306 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:05:47,306 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:05:47,306 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:05:47,322 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:05:47,322 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:05:47,322 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:05:47,322 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:05:51,851 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:51,851 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:05:51,851 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55531
2017-10-16 13:05:51,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:51,913 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55531
2017-10-16 13:05:51,913 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:05:51,913 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:05:51,913 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:51,913 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:51,913 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:51,913 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:51,913 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:51,913 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:51
2017-10-16 13:05:51,913 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:51,913 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:51,913 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:51,913 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:51,944 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:51,944 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:51,944 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:51,944 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:51,944 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:51,944 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:51,944 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:51,944 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:51,944 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:05:51,944 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:05:51,960 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:05:51,960 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:51,960 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:05:51,960 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:05:51,976 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:51,991 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:51,991 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current
2017-10-16 13:05:51,991 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:05:51,991 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:05:51,991 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:05:51,991 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:05:51,991 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000
2017-10-16 13:05:51,991 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:05:51,991 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:05:52,085 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:05:52,085 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 134 msecs
2017-10-16 13:05:52,085 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:05:52,085 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:05:52,085 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55534
2017-10-16 13:05:52,101 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55534 to access this namenode/service.
2017-10-16 13:05:52,101 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:05:52,101 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:52,101 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:05:52,101 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:05:52,101 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:05:52,101 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:05:52,101 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:05:52,101 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:05:52,116 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:05:52,116 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:05:52,116 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:05:52,116 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:05:52,116 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:05:52,116 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-10-16 13:05:52,116 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:05:52,116 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55534: starting
2017-10-16 13:05:52,116 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55534
2017-10-16 13:05:52,116 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:05:52,116 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:05:52,116 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:05:52,147 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:05:52,147 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:05:52,147 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:05:52,147 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:05:52,147 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:55541
2017-10-16 13:05:52,147 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:05:52,147 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:05:52,147 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:52,147 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:05:52,147 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:52,163 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:05:52,163 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:52,163 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:52,163 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55542
2017-10-16 13:05:52,163 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:52,210 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55542
2017-10-16 13:05:52,491 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:55609
2017-10-16 13:05:52,491 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:05:52,491 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:05:52,507 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:05:52,507 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55610
2017-10-16 13:05:52,507 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:55610
2017-10-16 13:05:52,522 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:05:52,522 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:05:52,522 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:55534 starting to offer service
2017-10-16 13:05:52,522 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:05:52,522 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55610: starting
2017-10-16 13:05:52,554 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:05:52,554 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:05:52,569 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:05:52,585 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:52,585 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data is not formatted for namespace 1779993483. Formatting...
2017-10-16 13:05:52,585 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:05:52,648 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:52,663 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:52,663 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-676672892-192.168.232.1-1508173547150 is not formatted for BP-676672892-192.168.232.1-1508173547150. Formatting ...
2017-10-16 13:05:52,663 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-676672892-192.168.232.1-1508173547150 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-676672892-192.168.232.1-1508173547150\current
2017-10-16 13:05:52,663 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:05:52,663 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:05:52,710 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1779993483;bpid=BP-676672892-192.168.232.1-1508173547150;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1779993483;c=0;bpid=BP-676672892-192.168.232.1-1508173547150;dnuuid=null
2017-10-16 13:05:52,726 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID 455527e3-aa0d-4702-b715-bfce2d0a356b
2017-10-16 13:05:52,741 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992
2017-10-16 13:05:52,741 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-676672892-192.168.232.1-1508173547150 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 7ms
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-676672892-192.168.232.1-1508173547150: 8ms
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 0ms
2017-10-16 13:05:52,757 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:05:52,757 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:05:52,757 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992): finished scanning block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:52,757 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508191634757 with interval 21600000
2017-10-16 13:05:52,773 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:05:52,773 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:05:52,773 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55534 beginning handshake with NN
2017-10-16 13:05:52,773 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55541, datanodeUuid=455527e3-aa0d-4702-b715-bfce2d0a356b, infoPort=55609, infoSecurePort=0, ipcPort=55610, storageInfo=lv=-56;cid=testClusterID;nsid=1779993483;c=0) storage 455527e3-aa0d-4702-b715-bfce2d0a356b
2017-10-16 13:05:52,773 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:05:52,773 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55541
2017-10-16 13:05:52,773 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55534 successfully registered with NN
2017-10-16 13:05:52,773 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:55534 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:05:52,788 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:05:52,788 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992 for DN 127.0.0.1:55541
2017-10-16 13:05:52,788 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55534 trying to claim ACTIVE state with txid=1
2017-10-16 13:05:52,788 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55534
2017-10-16 13:05:52,804 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992 node DatanodeRegistration(127.0.0.1:55541, datanodeUuid=455527e3-aa0d-4702-b715-bfce2d0a356b, infoPort=55609, infoSecurePort=0, ipcPort=55610, storageInfo=lv=-56;cid=testClusterID;nsid=1779993483;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2017-10-16 13:05:52,804 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992): no suitable block pools found to scan.  Waiting 1814399953 ms.
2017-10-16 13:05:52,819 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa354d96fe415c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 22 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:05:52,819 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:05:52,898 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:52,913 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:05:52,913 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(155)) - --starting Secondary Node
2017-10-16 13:05:52,976 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - SecondaryNameNode metrics system started (again)
2017-10-16 13:05:53,210 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:53,226 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:05:53,226 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:05:53,226 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:05:53,226 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:05:53,226 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:05:53,226 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:05:53,226 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:05:53
2017-10-16 13:05:53,226 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:05:53,226 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:53,226 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:05:53,226 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:05:53,241 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:05:53,241 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:05:53,241 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:05:53,241 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:05:53,241 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:05:53,241 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:05:53,241 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:05:53,241 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:05:53,241 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:05:53,241 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:05:53,257 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for secondary at: http://0.0.0.0:0
2017-10-16 13:05:57,788 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:05:57,788 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.secondary is not defined
2017-10-16 13:05:57,788 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:05:57,788 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2017-10-16 13:05:57,788 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:05:57,788 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:05:57,788 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55621
2017-10-16 13:05:57,788 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:05:57,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:55621
2017-10-16 13:05:57,851 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(278)) - Web server init done
2017-10-16 13:05:57,851 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(297)) - Checkpoint Period   :3600 secs (60 min)
2017-10-16 13:05:57,851 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(299)) - Log Size Trigger    :1000000 txns
2017-10-16 13:05:58,022 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/Zhibin/t0	dst=null	perm=Zhibin:supergroup:rw-r--r--	proto=rpc
2017-10-16 13:05:58,179 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992:NORMAL:127.0.0.1:55541|RBW]]} for /user/Zhibin/t0
2017-10-16 13:05:58,616 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-676672892-192.168.232.1-1508173547150:blk_1073741825_1001 src: /127.0.0.1:55624 dest: /127.0.0.1:55541
2017-10-16 13:05:58,757 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:55624, dest: /127.0.0.1:55541, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-613320068_1, offset: 0, srvID: 455527e3-aa0d-4702-b715-bfce2d0a356b, blockid: BP-676672892-192.168.232.1-1508173547150:blk_1073741825_1001, duration: 65197350
2017-10-16 13:05:58,757 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-676672892-192.168.232.1-1508173547150:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:05:58,773 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992:NORMAL:127.0.0.1:55541|RBW]]} for /user/Zhibin/t0
2017-10-16 13:05:58,788 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-676672892-192.168.232.1-1508173547150:blk_1073741826_1002 src: /127.0.0.1:55625 dest: /127.0.0.1:55541
2017-10-16 13:05:58,788 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:55625, dest: /127.0.0.1:55541, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-613320068_1, offset: 0, srvID: 455527e3-aa0d-4702-b715-bfce2d0a356b, blockid: BP-676672892-192.168.232.1-1508173547150:blk_1073741826_1002, duration: 4211860
2017-10-16 13:05:58,788 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-676672892-192.168.232.1-1508173547150:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:05:58,804 INFO  namenode.FSNamesystem (FSNamesystem.java:isCompleteBlock(3618)) - BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992:NORMAL:127.0.0.1:55541|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/Zhibin/t0
2017-10-16 13:05:58,804 INFO  namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-10-16 13:05:58,851 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:55541 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992:NORMAL:127.0.0.1:55541|RBW]]} size 4096
2017-10-16 13:05:58,866 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:55541 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992:NORMAL:127.0.0.1:55541|RBW]]} size 0
2017-10-16 13:05:59,257 INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3494)) - DIR* completeFile: /user/Zhibin/t0 is closed by DFSClient_NONMAPREDUCE_-613320068_1
2017-10-16 13:05:59,257 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(167)) - --file t0 created
2017-10-16 13:05:59,257 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(168)) - --doing checkpoint
2017-10-16 13:05:59,273 INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(5834)) - Roll Edit Log from 127.0.0.1
2017-10-16 13:05:59,273 INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1202)) - Rolling edit logs
2017-10-16 13:05:59,273 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:05:59,273 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 12 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 1 
2017-10-16 13:05:59,273 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:05:59,288 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 13
2017-10-16 13:05:59,476 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(455)) - Image has changed. Downloading updated image from NN.
2017-10-16 13:05:59,734 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:55531/imagetransfer?getimage=1&txid=0&storageInfo=-63:1779993483:0:testClusterID
2017-10-16 13:05:59,735 INFO  namenode.TransferFsImage (TransferFsImage.java:setTimeout(443)) - Image Transfer timeout configured to 60000 milliseconds
2017-10-16 13:05:59,941 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.07s at 0.00 KB/s
2017-10-16 13:05:59,941 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(115)) - Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2017-10-16 13:05:59,988 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:55531/imagetransfer?getedit=1&startTxId=1&endTxId=12&storageInfo=-63:1779993483:0:testClusterID
2017-10-16 13:06:00,019 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.03s at 0.00 KB/s
2017-10-16 13:06:00,019 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(168)) - Downloaded file edits_tmp_0000000000000000001-0000000000000000012_0000000002873364320 size 0 bytes.
2017-10-16 13:06:00,019 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:00,035 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:00,035 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000000
2017-10-16 13:06:00,035 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:00,051 INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(309)) - Checkpointer about to load edits from 1 stream(s).
2017-10-16 13:06:00,051 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000012 expecting start txid #1
2017-10-16 13:06:00,051 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:06:00,082 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000012 of size 724 edits # 12 loaded in 0 seconds
2017-10-16 13:06:00,082 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000012 using no compression
2017-10-16 13:06:00,098 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000012 of size 576 bytes saved in 0 seconds.
2017-10-16 13:06:00,160 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt
2017-10-16 13:06:00,160 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits
2017-10-16 13:06:00,332 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.07s at 0.00 KB/s
2017-10-16 13:06:00,332 INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(134)) - Downloaded file fsimage.ckpt_0000000000000000012 size 576 bytes.
2017-10-16 13:06:00,383 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2017-10-16 13:06:00,398 INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(237)) - Uploaded image with txid 12 to namenode at http://lambda-pluralsight:55531 in 0.194 seconds
2017-10-16 13:06:00,398 WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(566)) - Checkpoint done. New Image Size: 576
2017-10-16 13:06:00,398 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(170)) - --done checkpoint
2017-10-16 13:06:00,398 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:0
2017-10-16 13:06:00,508 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:06:00,508 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:06:00,508 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:06:00,508 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:06:00,508 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992) exiting.
2017-10-16 13:06:00,523 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:06:00,633 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55610
2017-10-16 13:06:00,633 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55610
2017-10-16 13:06:00,633 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:00,633 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55534 interrupted
2017-10-16 13:06:00,633 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55534
2017-10-16 13:06:00,633 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b)
2017-10-16 13:06:00,633 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:06:00,633 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:06:00,633 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:06:00,633 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:06:00,633 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:06:00,633 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:06:00,633 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:06:00,633 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:00,633 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 13
2017-10-16 13:06:00,633 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:00,633 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:00,633 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:06:00,633 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000013 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000013-0000000000000000014
2017-10-16 13:06:00,633 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:00,648 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55534
2017-10-16 13:06:00,664 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55534
2017-10-16 13:06:00,664 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:00,664 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:00,664 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:00,664 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:00,680 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:00,789 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(181)) - --cluster shutdown
2017-10-16 13:06:00,805 INFO  namenode.TestStartup (TestStartup.java:corruptNameNodeFiles(230)) - --removed dir K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name;len was =0
2017-10-16 13:06:00,805 INFO  namenode.TestStartup (TestStartup.java:corruptNameNodeFiles(245)) - --removed dir and recreated K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits;len was =0
2017-10-16 13:06:00,805 INFO  namenode.TestStartup (TestStartup.java:checkNameNodeFiles(257)) - -- about to start DFS cluster
2017-10-16 13:06:00,805 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
2017-10-16 13:06:00,805 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode [-importCheckpoint]
2017-10-16 13:06:00,805 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:06:00,805 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:06:00,805 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:06:05,344 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:05,344 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:05,344 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55629
2017-10-16 13:06:05,344 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:05,422 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55629
2017-10-16 13:06:05,438 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:05,438 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:05,438 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:05,454 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:05,454 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:05
2017-10-16 13:06:05,454 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:05,454 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:05,454 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:05,454 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:05,454 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:05,454 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:05,469 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:05,469 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:05,469 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:05,469 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:05,469 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:05,469 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:05,469 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:05,469 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:05,469 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:05,469 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:05,469 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:05,469 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:05,469 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:05,485 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:05,501 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:05,501 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(268)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name is not formatted.
2017-10-16 13:06:05,501 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(269)) - Formatting ...
2017-10-16 13:06:05,501 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(268)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits is not formatted.
2017-10-16 13:06:05,501 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(269)) - Formatting ...
2017-10-16 13:06:05,501 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:05,501 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:05,516 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:05,516 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current
2017-10-16 13:06:05,516 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:06:05,516 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-10-16 13:06:05,516 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 4 INodes.
2017-10-16 13:06:05,532 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:05,532 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 12 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000012
2017-10-16 13:06:05,547 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:05,547 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current
2017-10-16 13:06:05,547 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:06:05,547 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000012 using no compression
2017-10-16 13:06:05,563 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000012 of size 576 bytes saved in 0 seconds.
2017-10-16 13:06:05,594 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name
2017-10-16 13:06:05,594 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits
2017-10-16 13:06:05,688 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:05,688 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 13
2017-10-16 13:06:05,782 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:05,782 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 314 msecs
2017-10-16 13:06:05,782 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:06:05,782 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:05,782 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55632
2017-10-16 13:06:05,782 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55632 to access this namenode/service.
2017-10-16 13:06:05,782 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:05,813 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:05,813 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:05,813 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:05,813 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-10-16 13:06:05,813 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:05,813 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:05,813 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55632: starting
2017-10-16 13:06:05,813 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55632
2017-10-16 13:06:05,813 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:05,813 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:05,813 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:06:05,844 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:06:05,844 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:06:05,844 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:06:05,844 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:06:05,844 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:55639
2017-10-16 13:06:05,844 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:06:05,844 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:06:10,369 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:10,369 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:06:10,369 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:10,369 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:06:10,369 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:10,369 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:10,369 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55640
2017-10-16 13:06:10,369 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:10,432 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55640
2017-10-16 13:06:10,447 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:55707
2017-10-16 13:06:10,447 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:06:10,447 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:06:10,447 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:10,447 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55708
2017-10-16 13:06:10,447 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:55708
2017-10-16 13:06:10,447 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:06:10,447 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:06:10,447 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:55632 starting to offer service
2017-10-16 13:06:10,447 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:10,447 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55708: starting
2017-10-16 13:06:10,463 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:10,463 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:06:10,463 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:10,479 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:10,566 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:10,566 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:10,566 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:06:10,566 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:06:10,613 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1779993483;bpid=BP-676672892-192.168.232.1-1508173547150;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1779993483;c=0;bpid=BP-676672892-192.168.232.1-1508173547150;dnuuid=455527e3-aa0d-4702-b715-bfce2d0a356b
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(221)) - Cached dfsUsed found for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-676672892-192.168.232.1-1508173547150\current: 8407
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-676672892-192.168.232.1-1508173547150 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 8ms
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-676672892-192.168.232.1-1508173547150: 9ms
2017-10-16 13:06:10,613 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:10,628 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-676672892-192.168.232.1-1508173547150 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 3ms
2017-10-16 13:06:10,628 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 3ms
2017-10-16 13:06:10,659 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992): no suitable block pools found to scan.  Waiting 1814382098 ms.
2017-10-16 13:06:10,659 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508178570659 with interval 21600000
2017-10-16 13:06:10,659 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55632 beginning handshake with NN
2017-10-16 13:06:10,659 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55639, datanodeUuid=455527e3-aa0d-4702-b715-bfce2d0a356b, infoPort=55707, infoSecurePort=0, ipcPort=55708, storageInfo=lv=-56;cid=testClusterID;nsid=1779993483;c=0) storage 455527e3-aa0d-4702-b715-bfce2d0a356b
2017-10-16 13:06:10,659 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:10,659 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55639
2017-10-16 13:06:10,659 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55632 successfully registered with NN
2017-10-16 13:06:10,659 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:55632 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:06:10,659 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:10,659 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992 for DN 127.0.0.1:55639
2017-10-16 13:06:10,659 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55632 trying to claim ACTIVE state with txid=13
2017-10-16 13:06:10,659 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55632
2017-10-16 13:06:10,675 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:10,675 WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1200)) - Waiting for the Mini HDFS Cluster to start...
2017-10-16 13:06:10,675 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:10,675 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 5 secs
2017-10-16 13:06:10,675 INFO  hdfs.StateChange (FSNamesystem.java:leave(5251)) - STATE* Safe mode is OFF
2017-10-16 13:06:10,675 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 1 racks and 1 datanodes
2017-10-16 13:06:10,675 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:10,675 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992 node DatanodeRegistration(127.0.0.1:55639, datanodeUuid=455527e3-aa0d-4702-b715-bfce2d0a356b, infoPort=55707, infoSecurePort=0, ipcPort=55708, storageInfo=lv=-56;cid=testClusterID;nsid=1779993483;c=0), blocks: 2, hasStaleStorage: false, processing time: 1 msecs
2017-10-16 13:06:10,706 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 2
2017-10-16 13:06:10,706 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:10,706 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:10,706 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:10,706 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:10,706 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 19 msec
2017-10-16 13:06:10,706 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa3551c0de5d76,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 16 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2017-10-16 13:06:11,675 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:11,675 INFO  namenode.TestStartup (TestStartup.java:checkNameNodeFiles(266)) - --NN started with checkpoint option
2017-10-16 13:06:11,675 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(289)) - --image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000; len = 0; expected = 0
2017-10-16 13:06:11,675 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(294)) - -- edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000000; len = 0; expected = 0
2017-10-16 13:06:11,675 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:06:11,675 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:06:11,675 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:06:11,675 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:06:11,675 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-0191ad8a-e1e7-4143-a01b-5f8c060d4992) exiting.
2017-10-16 13:06:11,691 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55708
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55708
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:11,800 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55632 interrupted
2017-10-16 13:06:11,800 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b) service to lambda-pluralsight/127.0.0.1:55632
2017-10-16 13:06:11,800 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-676672892-192.168.232.1-1508173547150 (Datanode Uuid 455527e3-aa0d-4702-b715-bfce2d0a356b)
2017-10-16 13:06:11,800 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-676672892-192.168.232.1-1508173547150
2017-10-16 13:06:11,800 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:06:11,800 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:06:11,800 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:06:11,800 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:06:11,800 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:06:11,800 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:06:11,800 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:11,800 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 13
2017-10-16 13:06:11,800 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:11,800 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:11,800 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:06:11,800 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000013 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000013-0000000000000000014
2017-10-16 13:06:11,800 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55632
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55632
2017-10-16 13:06:11,800 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:11,800 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:11,816 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:11,816 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:11,816 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:11,925 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:06:11,925 INFO  namenode.TestStartup (TestStartup.java:testChkpointStartup2(309)) - --starting checkpointStartup2 - same directory for checkpoint
2017-10-16 13:06:11,941 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(144)) - --starting mini cluster
2017-10-16 13:06:11,941 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:11,941 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:11,941 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:11
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:11,941 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:11,941 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:11,941 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:11,941 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:11,941 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:11,941 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:11,941 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:11,956 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:11,956 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:11,956 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:11,956 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:11,956 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:11,956 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:11,956 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:11,956 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:11,956 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:11,956 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:12,050 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name has been successfully formatted.
2017-10-16 13:06:12,113 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits has been successfully formatted.
2017-10-16 13:06:12,113 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:06:12,128 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:06:12,175 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:06:12,175 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:06:12,175 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:06:12,175 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:06:12,175 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:06:16,723 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:16,723 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:16,723 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55719
2017-10-16 13:06:16,723 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:16,817 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55719
2017-10-16 13:06:16,817 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:16,817 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:16,817 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:16,817 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:16
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:16,817 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:16,817 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:16,817 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:16,817 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:16,832 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:16,832 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:16,832 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:16,832 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:16,832 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:16,832 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:16,832 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:16,832 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:16,832 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:16,832 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:16,832 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:16,832 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:16,832 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:16,864 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:16,864 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current
2017-10-16 13:06:16,864 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:06:16,864 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:06:16,864 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:16,864 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:16,864 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000
2017-10-16 13:06:16,864 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:16,864 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:06:16,942 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:16,942 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 122 msecs
2017-10-16 13:06:16,942 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:06:16,957 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:16,957 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55722
2017-10-16 13:06:16,957 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55722 to access this namenode/service.
2017-10-16 13:06:16,957 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:16,957 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:16,957 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:16,957 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:16,957 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:06:16,957 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:06:16,957 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:16,957 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:16,989 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:06:16,989 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:16,989 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:16,989 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:16,989 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:16,989 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 23 msec
2017-10-16 13:06:16,989 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:16,989 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55722: starting
2017-10-16 13:06:16,989 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55722
2017-10-16 13:06:16,989 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:16,989 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:16,989 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:06:16,989 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:06:16,989 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:06:16,989 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:06:16,989 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:06:16,989 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:55729
2017-10-16 13:06:16,989 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:06:17,004 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:06:17,004 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:17,004 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:06:17,004 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:17,004 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:06:17,004 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:17,004 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:17,004 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55730
2017-10-16 13:06:17,004 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:17,067 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55730
2017-10-16 13:06:17,082 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:55797
2017-10-16 13:06:17,082 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:06:17,082 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:06:17,082 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:17,082 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55798
2017-10-16 13:06:17,082 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:55798
2017-10-16 13:06:17,082 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:06:17,082 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:06:17,082 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:55722 starting to offer service
2017-10-16 13:06:17,082 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:17,082 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55798: starting
2017-10-16 13:06:17,082 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:17,082 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:17,082 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:06:17,114 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:17,114 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data is not formatted for namespace 1278234870. Formatting...
2017-10-16 13:06:17,114 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-46b3e7f6-4943-4cee-9fb4-0333145784fb for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:06:17,176 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:17,176 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:17,176 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1059358856-192.168.232.1-1508173571956 is not formatted for BP-1059358856-192.168.232.1-1508173571956. Formatting ...
2017-10-16 13:06:17,176 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1059358856-192.168.232.1-1508173571956 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1059358856-192.168.232.1-1508173571956\current
2017-10-16 13:06:17,192 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:17,192 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:17,239 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1278234870;bpid=BP-1059358856-192.168.232.1-1508173571956;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1278234870;c=0;bpid=BP-1059358856-192.168.232.1-1508173571956;dnuuid=null
2017-10-16 13:06:17,254 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID 123803ad-4f72-42e0-9749-815cce12b566
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-46b3e7f6-4943-4cee-9fb4-0333145784fb
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1059358856-192.168.232.1-1508173571956 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 1ms
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1059358856-192.168.232.1-1508173571956: 2ms
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 0ms
2017-10-16 13:06:17,254 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 0ms
2017-10-16 13:06:17,254 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:06:17,254 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508189273254 with interval 21600000
2017-10-16 13:06:17,254 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-46b3e7f6-4943-4cee-9fb4-0333145784fb): finished scanning block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:17,254 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55722 beginning handshake with NN
2017-10-16 13:06:17,270 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55729, datanodeUuid=123803ad-4f72-42e0-9749-815cce12b566, infoPort=55797, infoSecurePort=0, ipcPort=55798, storageInfo=lv=-56;cid=testClusterID;nsid=1278234870;c=0) storage 123803ad-4f72-42e0-9749-815cce12b566
2017-10-16 13:06:17,270 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:17,270 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-46b3e7f6-4943-4cee-9fb4-0333145784fb): no suitable block pools found to scan.  Waiting 1814399984 ms.
2017-10-16 13:06:17,270 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55729
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55722 successfully registered with NN
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:55722 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:06:17,270 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:17,270 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-46b3e7f6-4943-4cee-9fb4-0333145784fb for DN 127.0.0.1:55729
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55722 trying to claim ACTIVE state with txid=1
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55722
2017-10-16 13:06:17,270 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-46b3e7f6-4943-4cee-9fb4-0333145784fb node DatanodeRegistration(127.0.0.1:55729, datanodeUuid=123803ad-4f72-42e0-9749-815cce12b566, infoPort=55797, infoSecurePort=0, ipcPort=55798, storageInfo=lv=-56;cid=testClusterID;nsid=1278234870;c=0), blocks: 0, hasStaleStorage: false, processing time: 1 msecs
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa355349975b4e,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:06:17,270 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:17,301 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:17,301 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:17,301 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(155)) - --starting Secondary Node
2017-10-16 13:06:17,301 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - SecondaryNameNode metrics system started (again)
2017-10-16 13:06:17,317 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:17,317 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:17,317 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:17
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:17,317 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:17,317 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:17,317 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:17,317 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:17,317 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:17,317 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:17,317 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:17,332 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:17,332 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:17,332 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:17,332 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:17,332 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:17,332 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:17,332 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:17,332 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:17,332 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:17,332 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:17,332 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for secondary at: http://0.0.0.0:0
2017-10-16 13:06:21,856 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:21,856 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.secondary is not defined
2017-10-16 13:06:21,856 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:21,856 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2017-10-16 13:06:21,856 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:21,856 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:21,856 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55808
2017-10-16 13:06:21,856 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:21,919 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:55808
2017-10-16 13:06:21,919 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(278)) - Web server init done
2017-10-16 13:06:21,919 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(297)) - Checkpoint Period   :3600 secs (60 min)
2017-10-16 13:06:21,919 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(299)) - Log Size Trigger    :1000000 txns
2017-10-16 13:06:21,934 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/Zhibin/t0	dst=null	perm=Zhibin:supergroup:rw-r--r--	proto=rpc
2017-10-16 13:06:21,934 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-46b3e7f6-4943-4cee-9fb4-0333145784fb:NORMAL:127.0.0.1:55729|RBW]]} for /user/Zhibin/t0
2017-10-16 13:06:21,934 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1059358856-192.168.232.1-1508173571956:blk_1073741825_1001 src: /127.0.0.1:55811 dest: /127.0.0.1:55729
2017-10-16 13:06:21,934 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:55811, dest: /127.0.0.1:55729, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_675646641_1, offset: 0, srvID: 123803ad-4f72-42e0-9749-815cce12b566, blockid: BP-1059358856-192.168.232.1-1508173571956:blk_1073741825_1001, duration: 1703098
2017-10-16 13:06:21,934 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1059358856-192.168.232.1-1508173571956:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:06:21,934 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:55729 is added to blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-46b3e7f6-4943-4cee-9fb4-0333145784fb:NORMAL:127.0.0.1:55729|RBW]]} size 0
2017-10-16 13:06:21,934 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-46b3e7f6-4943-4cee-9fb4-0333145784fb:NORMAL:127.0.0.1:55729|RBW]]} for /user/Zhibin/t0
2017-10-16 13:06:21,934 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1059358856-192.168.232.1-1508173571956:blk_1073741826_1002 src: /127.0.0.1:55812 dest: /127.0.0.1:55729
2017-10-16 13:06:21,950 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:55812, dest: /127.0.0.1:55729, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_675646641_1, offset: 0, srvID: 123803ad-4f72-42e0-9749-815cce12b566, blockid: BP-1059358856-192.168.232.1-1508173571956:blk_1073741826_1002, duration: 1354751
2017-10-16 13:06:21,950 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1059358856-192.168.232.1-1508173571956:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:06:21,950 INFO  namenode.FSNamesystem (FSNamesystem.java:isCompleteBlock(3618)) - BLOCK* blk_1073741826_1002{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-46b3e7f6-4943-4cee-9fb4-0333145784fb:NORMAL:127.0.0.1:55729|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/Zhibin/t0
2017-10-16 13:06:21,950 INFO  namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-10-16 13:06:21,950 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:55729 is added to blk_1073741826_1002{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-46b3e7f6-4943-4cee-9fb4-0333145784fb:NORMAL:127.0.0.1:55729|RBW]]} size 4096
2017-10-16 13:06:22,356 INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3494)) - DIR* completeFile: /user/Zhibin/t0 is closed by DFSClient_NONMAPREDUCE_675646641_1
2017-10-16 13:06:22,356 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(167)) - --file t0 created
2017-10-16 13:06:22,356 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(168)) - --doing checkpoint
2017-10-16 13:06:22,356 INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(5834)) - Roll Edit Log from 127.0.0.1
2017-10-16 13:06:22,356 INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1202)) - Rolling edit logs
2017-10-16 13:06:22,356 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:06:22,356 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 12 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 1 
2017-10-16 13:06:22,356 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:06:22,356 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 13
2017-10-16 13:06:22,544 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(455)) - Image has changed. Downloading updated image from NN.
2017-10-16 13:06:22,544 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:55719/imagetransfer?getimage=1&txid=0&storageInfo=-63:1278234870:0:testClusterID
2017-10-16 13:06:22,575 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.03s at 0.00 KB/s
2017-10-16 13:06:22,575 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(115)) - Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2017-10-16 13:06:22,622 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:55719/imagetransfer?getedit=1&startTxId=1&endTxId=12&storageInfo=-63:1278234870:0:testClusterID
2017-10-16 13:06:22,653 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.02s at 0.00 KB/s
2017-10-16 13:06:22,653 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(168)) - Downloaded file edits_tmp_0000000000000000001-0000000000000000012_0000000002873386956 size 0 bytes.
2017-10-16 13:06:22,653 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:22,653 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:22,653 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000000
2017-10-16 13:06:22,653 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:22,653 INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(309)) - Checkpointer about to load edits from 1 stream(s).
2017-10-16 13:06:22,653 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\edits_0000000000000000001-0000000000000000012 expecting start txid #1
2017-10-16 13:06:22,653 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:06:22,653 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\edits_0000000000000000001-0000000000000000012 of size 723 edits # 12 loaded in 0 seconds
2017-10-16 13:06:22,653 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000012 using no compression
2017-10-16 13:06:22,669 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000012 of size 576 bytes saved in 0 seconds.
2017-10-16 13:06:22,716 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt
2017-10-16 13:06:22,794 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.06s at 0.00 KB/s
2017-10-16 13:06:22,794 INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(134)) - Downloaded file fsimage.ckpt_0000000000000000012 size 576 bytes.
2017-10-16 13:06:22,856 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2017-10-16 13:06:22,856 INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(237)) - Uploaded image with txid 12 to namenode at http://lambda-pluralsight:55719 in 0.134 seconds
2017-10-16 13:06:22,856 WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(566)) - Checkpoint done. New Image Size: 576
2017-10-16 13:06:22,856 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(170)) - --done checkpoint
2017-10-16 13:06:22,856 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:0
2017-10-16 13:06:22,966 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:06:22,966 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:06:22,966 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:06:22,966 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:06:22,966 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-46b3e7f6-4943-4cee-9fb4-0333145784fb) exiting.
2017-10-16 13:06:22,981 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55798
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55798
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:23,091 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55722 interrupted
2017-10-16 13:06:23,091 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55722
2017-10-16 13:06:23,091 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566)
2017-10-16 13:06:23,091 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:23,091 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:06:23,091 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:06:23,091 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:06:23,091 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:06:23,091 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:06:23,091 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:06:23,091 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:23,091 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 13
2017-10-16 13:06:23,091 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:23,091 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:23,091 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:06:23,091 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000013 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000013-0000000000000000014
2017-10-16 13:06:23,091 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55722
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55722
2017-10-16 13:06:23,091 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:23,091 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:23,091 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:23,091 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:23,106 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:23,216 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(181)) - --cluster shutdown
2017-10-16 13:06:23,231 INFO  namenode.TestStartup (TestStartup.java:corruptNameNodeFiles(230)) - --removed dir K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name;len was =0
2017-10-16 13:06:23,231 INFO  namenode.TestStartup (TestStartup.java:corruptNameNodeFiles(245)) - --removed dir and recreated K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits;len was =0
2017-10-16 13:06:23,231 INFO  namenode.TestStartup (TestStartup.java:checkNameNodeFiles(257)) - -- about to start DFS cluster
2017-10-16 13:06:23,231 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
2017-10-16 13:06:23,231 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode [-importCheckpoint]
2017-10-16 13:06:23,231 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:06:23,231 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:06:23,231 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:06:27,765 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:27,765 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:27,765 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55815
2017-10-16 13:06:27,765 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:27,828 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55815
2017-10-16 13:06:27,843 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:27,843 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:27,843 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:27,859 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:27,859 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:27
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:27,859 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:27,859 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:27,859 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:27,859 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:27,859 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:27,859 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:27,859 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:27,875 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:27,875 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:27,875 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:27,875 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:27,875 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:27,875 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:27,875 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:27,875 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:27,875 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:27,890 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:27,921 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(268)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name is not formatted.
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(269)) - Formatting ...
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(268)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits is not formatted.
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:recoverTransitionRead(269)) - Formatting ...
2017-10-16 13:06:27,921 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:27,921 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:27,921 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000012, cpktTxId=0000000000000000012)
2017-10-16 13:06:27,921 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 4 INodes.
2017-10-16 13:06:27,921 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:27,921 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 12 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000012
2017-10-16 13:06:27,937 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:27,937 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current
2017-10-16 13:06:27,937 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:06:27,937 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000012 using no compression
2017-10-16 13:06:27,937 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000012 of size 576 bytes saved in 0 seconds.
2017-10-16 13:06:28,047 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name
2017-10-16 13:06:28,047 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits
2017-10-16 13:06:28,234 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:28,234 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 13
2017-10-16 13:06:28,312 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:28,312 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 447 msecs
2017-10-16 13:06:28,312 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:06:28,312 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:28,312 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55818
2017-10-16 13:06:28,328 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55818 to access this namenode/service.
2017-10-16 13:06:28,328 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:28,328 WARN  namenode.FSNamesystem (FSNamesystem.java:getStorageDirs(1388)) - !!! WARNING !!!
	The NameNode currently runs without persistent storage.
	Any changes to the file system meta-data may be lost.
	Recommended actions:
		- shutdown and restart NameNode with configured "dfs.namenode.edits.dir.required" in hdfs-site.xml;
		- use Backup Node as a persistent and up-to-date storage of the file system meta-data.
2017-10-16 13:06:28,328 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:28,328 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:28,328 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 2 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-10-16 13:06:28,328 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:28,343 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:28,343 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55818: starting
2017-10-16 13:06:28,375 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55818
2017-10-16 13:06:28,375 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:28,390 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:28,390 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:06:32,924 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:06:32,924 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:06:32,924 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:06:32,924 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:06:32,924 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:55825
2017-10-16 13:06:32,924 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:06:32,924 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:06:32,924 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:32,924 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:06:32,924 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:32,924 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:06:32,924 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:32,924 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:32,924 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55826
2017-10-16 13:06:32,924 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:32,986 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55826
2017-10-16 13:06:33,002 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:55893
2017-10-16 13:06:33,002 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:06:33,002 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:06:33,002 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:33,002 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55894
2017-10-16 13:06:33,002 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:55894
2017-10-16 13:06:33,002 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:06:33,002 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:06:33,002 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:55818 starting to offer service
2017-10-16 13:06:33,002 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:33,002 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55894: starting
2017-10-16 13:06:33,002 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:33,002 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:06:33,002 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:33,002 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:33,018 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:33,018 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:33,049 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1278234870;bpid=BP-1059358856-192.168.232.1-1508173571956;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1278234870;c=0;bpid=BP-1059358856-192.168.232.1-1508173571956;dnuuid=123803ad-4f72-42e0-9749-815cce12b566
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-46b3e7f6-4943-4cee-9fb4-0333145784fb
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(221)) - Cached dfsUsed found for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1059358856-192.168.232.1-1508173571956\current: 8408
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1059358856-192.168.232.1-1508173571956 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 1ms
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1059358856-192.168.232.1-1508173571956: 2ms
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1059358856-192.168.232.1-1508173571956 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 0ms
2017-10-16 13:06:33,049 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:06:33,049 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-46b3e7f6-4943-4cee-9fb4-0333145784fb): no suitable block pools found to scan.  Waiting 1814384205 ms.
2017-10-16 13:06:33,049 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508189984049 with interval 21600000
2017-10-16 13:06:33,049 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55818 beginning handshake with NN
2017-10-16 13:06:33,049 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55825, datanodeUuid=123803ad-4f72-42e0-9749-815cce12b566, infoPort=55893, infoSecurePort=0, ipcPort=55894, storageInfo=lv=-56;cid=testClusterID;nsid=1278234870;c=0) storage 123803ad-4f72-42e0-9749-815cce12b566
2017-10-16 13:06:33,049 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:33,049 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55825
2017-10-16 13:06:33,049 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55818 successfully registered with NN
2017-10-16 13:06:33,064 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:55818 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:06:33,064 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:33,064 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-46b3e7f6-4943-4cee-9fb4-0333145784fb for DN 127.0.0.1:55825
2017-10-16 13:06:33,064 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55818 trying to claim ACTIVE state with txid=13
2017-10-16 13:06:33,064 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55818
2017-10-16 13:06:33,064 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:33,064 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 5 secs
2017-10-16 13:06:33,064 INFO  hdfs.StateChange (FSNamesystem.java:leave(5251)) - STATE* Safe mode is OFF
2017-10-16 13:06:33,064 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 1 racks and 1 datanodes
2017-10-16 13:06:33,064 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:33,064 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-46b3e7f6-4943-4cee-9fb4-0333145784fb node DatanodeRegistration(127.0.0.1:55825, datanodeUuid=123803ad-4f72-42e0-9749-815cce12b566, infoPort=55893, infoSecurePort=0, ipcPort=55894, storageInfo=lv=-56;cid=testClusterID;nsid=1278234870;c=0), blocks: 2, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:06:33,064 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa3556f6e3fbfd,  containing 1 storage report(s), of which we sent 1. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back no commands.
2017-10-16 13:06:33,064 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 2
2017-10-16 13:06:33,064 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:33,064 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:33,064 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:33,064 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:33,064 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2017-10-16 13:06:33,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:33,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:33,111 INFO  namenode.TestStartup (TestStartup.java:checkNameNodeFiles(266)) - --NN started with checkpoint option
2017-10-16 13:06:33,111 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(289)) - --image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000; len = 0; expected = 0
2017-10-16 13:06:33,111 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(294)) - -- edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000000; len = 0; expected = 0
2017-10-16 13:06:33,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:06:33,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:06:33,111 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:06:33,111 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:06:33,111 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-46b3e7f6-4943-4cee-9fb4-0333145784fb) exiting.
2017-10-16 13:06:33,127 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55894
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55894
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:33,236 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55818 interrupted
2017-10-16 13:06:33,236 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566) service to lambda-pluralsight/127.0.0.1:55818
2017-10-16 13:06:33,236 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1059358856-192.168.232.1-1508173571956 (Datanode Uuid 123803ad-4f72-42e0-9749-815cce12b566)
2017-10-16 13:06:33,236 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1059358856-192.168.232.1-1508173571956
2017-10-16 13:06:33,236 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:06:33,236 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:06:33,236 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:06:33,236 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:06:33,236 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:06:33,236 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:06:33,236 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:33,236 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 13
2017-10-16 13:06:33,236 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:33,236 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:33,236 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:06:33,236 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_inprogress_0000000000000000013 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\edits\current\edits_0000000000000000013-0000000000000000014
2017-10-16 13:06:33,236 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55818
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55818
2017-10-16 13:06:33,236 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:33,236 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:33,236 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:33,236 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:33,252 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:33,377 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:06:33,393 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:06:33,408 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:33,408 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:33,424 INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(88)) - Adding lambda-pluralsight to the list of included hosts from /K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/build/test/data/work-dir/restartnn/hosts
2017-10-16 13:06:33,424 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:33,424 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:33
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:33,424 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:33,424 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:33,424 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:33,424 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:33,424 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:33,424 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:33,424 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:33,424 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:33,424 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:33,424 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:33,424 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:33,439 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:33,439 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:33,439 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:33,439 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:33,439 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:33,439 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:33,439 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:33,439 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:33,439 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:33,439 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:33,502 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1 has been successfully formatted.
2017-10-16 13:06:33,643 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2 has been successfully formatted.
2017-10-16 13:06:33,643 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:06:33,643 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:06:33,674 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:06:33,705 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:06:33,814 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:06:33,814 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:06:33,814 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:06:33,814 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:06:33,814 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:06:38,345 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:38,345 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:38,345 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55905
2017-10-16 13:06:38,345 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:38,391 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55905
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:38,391 INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(88)) - Adding lambda-pluralsight to the list of included hosts from /K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/build/test/data/work-dir/restartnn/hosts
2017-10-16 13:06:38,391 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:38,391 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:38
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:38,391 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:38,391 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:38,391 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:38,391 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:38,391 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:38,391 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:38,407 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:38,407 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:38,407 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:38,407 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:38,407 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:38,407 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:38,407 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:38,407 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:38,407 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:38,407 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:38,423 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:38,454 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:38,454 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:06:38,454 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:06:38,454 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:06:38,454 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:06:38,454 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:38,454 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:38,454 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:06:38,454 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:38,454 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:06:38,563 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:38,563 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 167 msecs
2017-10-16 13:06:38,563 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:06:38,563 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:38,579 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55908
2017-10-16 13:06:38,579 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:55908 to access this namenode/service.
2017-10-16 13:06:38,579 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:38,579 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:38,579 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:38,579 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:38,579 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:06:38,579 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:06:38,579 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:38,579 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:38,595 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:06:38,595 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:38,595 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:38,595 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:38,595 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:38,595 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2017-10-16 13:06:38,595 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:38,595 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55908: starting
2017-10-16 13:06:38,595 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55908
2017-10-16 13:06:38,595 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:38,595 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:38,595 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setupDatanodeAddress(2797)) - Adding datanode 127.0.0.1:55915 to hosts file /K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/build/test/data/work-dir/restartnn/hosts
2017-10-16 13:06:38,595 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2017-10-16 13:06:38,626 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:06:38,626 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:06:38,626 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:06:38,626 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:06:38,626 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:55915
2017-10-16 13:06:38,626 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:06:38,626 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:06:38,626 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:38,626 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:06:38,626 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:38,626 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:06:38,626 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:38,626 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:38,626 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55916
2017-10-16 13:06:38,626 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:38,673 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:55916
2017-10-16 13:06:38,688 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:55983
2017-10-16 13:06:38,688 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:06:38,688 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:06:38,688 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:38,688 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55984
2017-10-16 13:06:38,688 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:55984
2017-10-16 13:06:38,688 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:06:38,688 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:06:38,688 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:55908 starting to offer service
2017-10-16 13:06:38,704 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55984: starting
2017-10-16 13:06:38,704 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:38,704 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:38,704 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2017-10-16 13:06:38,704 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:38,720 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:38,720 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1 is not formatted for namespace 527267118. Formatting...
2017-10-16 13:06:38,720 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1
2017-10-16 13:06:38,798 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:38,798 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2 is not formatted for namespace 527267118. Formatting...
2017-10-16 13:06:38,798 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-4d9c9477-05c7-4246-a306-db46f9b23279 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2
2017-10-16 13:06:38,813 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:38,813 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:38,860 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:38,860 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:38,860 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-385201039-192.168.232.1-1508173593439 is not formatted for BP-385201039-192.168.232.1-1508173593439. Formatting ...
2017-10-16 13:06:38,860 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-385201039-192.168.232.1-1508173593439 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-385201039-192.168.232.1-1508173593439\current
2017-10-16 13:06:38,923 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:38,923 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:38,923 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:38,923 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:38,923 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-385201039-192.168.232.1-1508173593439 is not formatted for BP-385201039-192.168.232.1-1508173593439. Formatting ...
2017-10-16 13:06:38,923 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-385201039-192.168.232.1-1508173593439 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-385201039-192.168.232.1-1508173593439\current
2017-10-16 13:06:38,970 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=527267118;bpid=BP-385201039-192.168.232.1-1508173593439;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=527267118;c=0;bpid=BP-385201039-192.168.232.1-1508173593439;dnuuid=null
2017-10-16 13:06:39,032 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:06:39,032 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:06:39,032 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID f759d557-c65b-488c-bb35-7b823548ba51
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current, StorageType: DISK
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-4d9c9477-05c7-4246-a306-db46f9b23279
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current, StorageType: DISK
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current...
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current...
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-385201039-192.168.232.1-1508173593439 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current: 2ms
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-385201039-192.168.232.1-1508173593439 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current: 1ms
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-385201039-192.168.232.1-1508173593439: 3ms
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current...
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current...
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current: 1ms
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current: 1ms
2017-10-16 13:06:39,032 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:06:39,032 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1
2017-10-16 13:06:39,032 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508181079032 with interval 21600000
2017-10-16 13:06:39,032 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-385201039-192.168.232.1-1508173593439 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2
2017-10-16 13:06:39,048 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55908 beginning handshake with NN
2017-10-16 13:06:39,048 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11): finished scanning block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:39,048 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-4d9c9477-05c7-4246-a306-db46f9b23279): finished scanning block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:39,048 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0) storage f759d557-c65b-488c-bb35-7b823548ba51
2017-10-16 13:06:39,048 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:39,048 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55915
2017-10-16 13:06:39,048 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11): no suitable block pools found to scan.  Waiting 1814399984 ms.
2017-10-16 13:06:39,048 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-4d9c9477-05c7-4246-a306-db46f9b23279): no suitable block pools found to scan.  Waiting 1814399984 ms.
2017-10-16 13:06:39,048 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:55908 successfully registered with NN
2017-10-16 13:06:39,048 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:55908 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:06:39,048 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:39,048 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11 for DN 127.0.0.1:55915
2017-10-16 13:06:39,048 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-4d9c9477-05c7-4246-a306-db46f9b23279 for DN 127.0.0.1:55915
2017-10-16 13:06:39,048 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908 trying to claim ACTIVE state with txid=1
2017-10-16 13:06:39,048 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908
2017-10-16 13:06:39,048 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11 node DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0), blocks: 0, hasStaleStorage: true, processing time: 0 msecs
2017-10-16 13:06:39,063 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-4d9c9477-05c7-4246-a306-db46f9b23279 node DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:06:39,063 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa35585be210eb,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:06:39,063 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:39,142 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:39,142 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:39,142 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownNameNode(1770)) - Shutting down the namenode
2017-10-16 13:06:39,142 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:39,142 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:06:39,142 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:39,142 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:39,142 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 0 
2017-10-16 13:06:39,142 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:06:39,142 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:06:39,142 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:39,142 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55908
2017-10-16 13:06:39,142 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55908
2017-10-16 13:06:39,142 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:39,142 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:39,157 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:39,157 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:39,157 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:39,266 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:06:39,266 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:06:39,266 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://lambda-pluralsight:55908
2017-10-16 13:06:39,266 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use lambda-pluralsight:55908 to access this namenode/service.
2017-10-16 13:06:39,266 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:55905
2017-10-16 13:06:42,097 WARN  datanode.DataNode (BPServiceActor.java:offerService(725)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "zbhuang_home/192.168.232.1"; destination host is: "lambda-pluralsight":55908; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy22.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2017-10-16 13:06:43,808 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:43,808 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:43,808 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 55905
2017-10-16 13:06:43,808 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:43,870 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55905
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:43,870 INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(88)) - Adding lambda-pluralsight to the list of included hosts from /K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/build/test/data/work-dir/restartnn/hosts
2017-10-16 13:06:43,870 INFO  util.HostsFileReader (HostsFileReader.java:readFileToSetWithFileInputStream(88)) - Adding 127.0.0.1:55915 to the list of included hosts from /K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/build/test/data/work-dir/restartnn/hosts
2017-10-16 13:06:43,870 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:43,870 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:43
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:43,870 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:43,870 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:43,870 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:43,886 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:43,886 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:43,886 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:43,886 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:43,886 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:43,886 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:43,886 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:06:43,886 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:43,886 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:43,886 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:43,886 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:43,886 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:43,886 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:43,886 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:43,886 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:43,886 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:06:43,886 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:06:43,886 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:06:43,886 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:43,886 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:43,902 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:06:43,902 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@50756c76 expecting start txid #1
2017-10-16 13:06:43,902 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002, K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:06:43,902 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002' to transaction ID 1
2017-10-16 13:06:43,902 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002, K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:06:43,902 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:43,902 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 3
2017-10-16 13:06:43,995 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:43,995 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 111 msecs
2017-10-16 13:06:43,995 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:55908
2017-10-16 13:06:43,995 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:44,058 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 55908
2017-10-16 13:06:44,074 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:44,074 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:44,074 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:44,074 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:44,074 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:06:44,074 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:06:44,074 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:44,074 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:44,089 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:06:44,089 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:44,089 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:44,089 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:44,089 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:44,089 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-10-16 13:06:44,089 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:44,089 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 55908: starting
2017-10-16 13:06:44,089 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:55908
2017-10-16 13:06:44,089 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:44,089 WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1200)) - Waiting for the Mini HDFS Cluster to start...
2017-10-16 13:06:44,089 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:45,074 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(607)) - DatanodeCommand action : DNA_REGISTER from lambda-pluralsight/127.0.0.1:55908 with active state
2017-10-16 13:06:45,074 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908 beginning handshake with NN
2017-10-16 13:06:45,089 WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1200)) - Waiting for the Mini HDFS Cluster to start...
2017-10-16 13:06:45,089 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0) storage f759d557-c65b-488c-bb35-7b823548ba51
2017-10-16 13:06:45,089 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:45,089 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:55915
2017-10-16 13:06:45,089 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908 successfully registered with NN
2017-10-16 13:06:45,089 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:45,089 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11 for DN 127.0.0.1:55915
2017-10-16 13:06:45,089 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-4d9c9477-05c7-4246-a306-db46f9b23279 for DN 127.0.0.1:55915
2017-10-16 13:06:45,089 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11 node DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0), blocks: 0, hasStaleStorage: true, processing time: 0 msecs
2017-10-16 13:06:45,089 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-4d9c9477-05c7-4246-a306-db46f9b23279 node DatanodeRegistration(127.0.0.1:55915, datanodeUuid=f759d557-c65b-488c-bb35-7b823548ba51, infoPort=55983, infoSecurePort=0, ipcPort=55984, storageInfo=lv=-56;cid=testClusterID;nsid=527267118;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:06:45,089 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa3559c42c34f1,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:06:45,089 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:46,094 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(1833)) - Restarted the namenode
2017-10-16 13:06:46,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:06:46,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:06:46,111 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:06:46,111 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:06:46,111 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:06:46,111 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-4179857d-c5d5-4722-9a70-ed4c1aaafe11) exiting.
2017-10-16 13:06:46,111 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-4d9c9477-05c7-4246-a306-db46f9b23279) exiting.
2017-10-16 13:06:46,127 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55984
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55984
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:46,236 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908 interrupted
2017-10-16 13:06:46,236 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51) service to lambda-pluralsight/127.0.0.1:55908
2017-10-16 13:06:46,236 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-385201039-192.168.232.1-1508173593439 (Datanode Uuid f759d557-c65b-488c-bb35-7b823548ba51)
2017-10-16 13:06:46,236 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-385201039-192.168.232.1-1508173593439
2017-10-16 13:06:46,236 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:06:46,236 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:06:46,236 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:06:46,236 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:06:46,236 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:06:46,236 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:06:46,236 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:46,236 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 3
2017-10-16 13:06:46,236 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:46,236 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:46,236 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 0 
2017-10-16 13:06:46,236 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000003 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000003-0000000000000000004
2017-10-16 13:06:46,236 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000003 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000003-0000000000000000004
2017-10-16 13:06:46,236 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 55908
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 55908
2017-10-16 13:06:46,236 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:46,236 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:46,252 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:46,252 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:46,252 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:55905
2017-10-16 13:06:46,408 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:06:46,424 INFO  namenode.TestStartup (TestStartup.java:testCompression(424)) - Test compressing image.
2017-10-16 13:06:46,455 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:967)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:343)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:184)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:433)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:46,455 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:46,455 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:973)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:343)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:184)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:433)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:46,470 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
Formatting using clusterid: testClusterID
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:46,470 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:46,470 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:46
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:46,470 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:46,470 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:46,470 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:46,470 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:46,470 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:46,470 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:46,470 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:46,486 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:46,486 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:46,486 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:06:46,486 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:46,486 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:46,486 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:46,486 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:46,486 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:46,486 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:46,486 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:46,486 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:46,486 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:46,486 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-581092933-192.168.232.1-1508173606486
2017-10-16 13:06:46,549 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name has been successfully formatted.
2017-10-16 13:06:46,549 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:06:46,564 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:06:46,595 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:06:46,595 INFO  namenode.TestStartup (TestStartup.java:testCompression(436)) - Create an uncompressed fsimage
2017-10-16 13:06:46,595 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://localhost:0
2017-10-16 13:06:46,595 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:06:51,118 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:51,118 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:51,118 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56004
2017-10-16 13:06:51,118 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:51,196 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:06:51,196 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:616)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:437)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:51,196 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:51,196 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:618)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:437)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:51,212 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:51,212 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:51,212 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:51,212 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:671)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:437)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:51,212 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:51,212 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:672)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:437)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:51,212 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:51,212 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:51,212 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:51,212 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:51,228 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:51
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:51,228 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:51,228 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:51,228 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:51,228 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:51,228 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:51,228 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:51,228 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:51,243 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:06:51,243 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:51,243 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:51,243 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:51,243 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:51,243 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:51,243 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:51,243 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:51,243 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:51,243 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:51,243 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:51,243 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current
2017-10-16 13:06:51,243 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:06:51,243 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:06:51,243 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:06:51,243 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:51,243 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000000
2017-10-16 13:06:51,243 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:51,243 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:06:51,306 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:51,306 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 75 msecs
2017-10-16 13:06:51,306 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to localhost:0
2017-10-16 13:06:51,306 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:51,321 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56007
2017-10-16 13:06:51,321 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use localhost:56007 to access this namenode/service.
2017-10-16 13:06:51,321 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:51,321 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:120)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1058)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:679)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:665)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:437)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:51,321 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:51,337 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:51,337 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:51,337 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:51,337 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:06:51,337 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:06:51,337 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:51,337 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:51,353 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:06:51,353 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:51,353 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:51,353 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:51,353 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:51,353 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-10-16 13:06:51,353 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:51,353 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56007: starting
2017-10-16 13:06:51,353 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: localhost/127.0.0.1:56007
2017-10-16 13:06:51,353 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:51,353 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:51,353 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode is ON. 
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2017-10-16 13:06:51,353 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:06:51,353 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:06:51,353 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 3 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 4 SyncTimes(ms): 1 
2017-10-16 13:06:51,353 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000001-0000000000000000003
2017-10-16 13:06:51,353 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000003 using no compression
2017-10-16 13:06:51,368 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000003 of size 441 bytes saved in 0 seconds.
2017-10-16 13:06:51,415 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2017-10-16 13:06:51,431 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 4
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(5010)) - New namespace image has been created
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:51,478 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 4
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:51,478 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:06:51,478 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000004 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000004-0000000000000000005
2017-10-16 13:06:51,478 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:51,478 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56007
2017-10-16 13:06:51,478 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56007
2017-10-16 13:06:51,478 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:51,478 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:51,478 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:51,478 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:06:51,603 INFO  namenode.TestStartup (TestStartup.java:testCompression(448)) - Read an uncomressed image and store it compressed using default codec.
2017-10-16 13:06:51,603 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://localhost:56007
2017-10-16 13:06:51,603 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use localhost:56007 to access this namenode/service.
2017-10-16 13:06:51,603 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:56004
2017-10-16 13:06:56,154 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:06:56,154 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:06:56,154 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56004
2017-10-16 13:06:56,154 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:06:56,217 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:06:56,217 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:616)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:450)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:56,217 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:56,217 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:618)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:450)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:56,232 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:56,232 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:56,232 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:06:56,232 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:671)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:450)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:56,232 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:56,232 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:672)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:450)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:56,248 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:06:56,248 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:06:56,248 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:06:56
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:06:56,248 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:06:56,248 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:06:56,248 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:06:56,248 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:06:56,248 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:06:56,248 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:06:56,248 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:06:56,263 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:06:56,263 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:06:56,263 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:06:56,263 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:06:56,263 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:06:56,263 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:06:56,263 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:06:56,263 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:06:56,263 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:06:56,263 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:06:56,263 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:06:56,263 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:06:56,263 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:06:56,263 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current
2017-10-16 13:06:56,263 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000003, cpktTxId=0000000000000000003)
2017-10-16 13:06:56,263 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 2 INodes.
2017-10-16 13:06:56,263 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:06:56,263 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 3 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000003
2017-10-16 13:06:56,263 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@176f7f3b expecting start txid #4
2017-10-16 13:06:56,263 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000004-0000000000000000005
2017-10-16 13:06:56,263 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000004-0000000000000000005' to transaction ID 4
2017-10-16 13:06:56,263 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000004-0000000000000000005 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:06:56,279 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:06:56,279 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 6
2017-10-16 13:06:56,326 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:06:56,326 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 69 msecs
2017-10-16 13:06:56,326 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to localhost:56007
2017-10-16 13:06:56,326 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:06:56,326 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56007
2017-10-16 13:06:56,326 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:06:56,326 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:120)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1058)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:679)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:665)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:450)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:06:56,342 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:06:56,342 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:56,342 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:06:56,342 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:06:56,342 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:06:56,342 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:06:56,342 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:06:56,342 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:06:56,357 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:06:56,357 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:06:56,357 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:06:56,357 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:06:56,357 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:06:56,357 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2017-10-16 13:06:56,357 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56007: starting
2017-10-16 13:06:56,357 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:06:56,357 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: localhost/127.0.0.1:56007
2017-10-16 13:06:56,357 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:06:56,357 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:06:56,357 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode is ON. 
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2017-10-16 13:06:56,357 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:06:56,357 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 6
2017-10-16 13:06:56,357 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:06:56,357 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000006 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000006-0000000000000000007
2017-10-16 13:06:56,560 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000007 using codec org.apache.hadoop.io.compress.DefaultCodec
2017-10-16 13:06:56,670 INFO  zlib.ZlibFactory (ZlibFactory.java:<clinit>(49)) - Successfully loaded & initialized native-zlib library
2017-10-16 13:06:56,670 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,670 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.deflate]
2017-10-16 13:06:56,685 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000007 of size 532 bytes saved in 0 seconds.
2017-10-16 13:06:56,748 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 3
2017-10-16 13:06:56,748 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:06:56,857 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 8
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(5010)) - New namespace image has been created
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:56,998 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 8
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:06:56,998 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:06:56,998 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000008 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000008-0000000000000000009
2017-10-16 13:06:56,998 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:06:56,998 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56007
2017-10-16 13:06:56,998 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56007
2017-10-16 13:06:56,998 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:06:56,998 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:06:56,998 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:06:57,013 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:06:57,123 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(211)) - Stopping NameNode metrics system...
2017-10-16 13:06:57,123 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(217)) - NameNode metrics system stopped.
2017-10-16 13:06:57,123 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(605)) - NameNode metrics system shutdown complete.
2017-10-16 13:06:57,123 INFO  namenode.TestStartup (TestStartup.java:testCompression(453)) - Read a compressed image and store it using a different codec.
2017-10-16 13:06:57,123 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://localhost:56007
2017-10-16 13:06:57,123 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use localhost:56007 to access this namenode/service.
2017-10-16 13:06:57,123 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:56004
2017-10-16 13:07:01,647 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:01,647 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:01,647 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56004
2017-10-16 13:07:01,647 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:01,709 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:01,709 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:616)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:456)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:01,709 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:01,709 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:618)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:456)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:01,725 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:01,725 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:01,725 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:01,725 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:671)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:456)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:01,725 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:01,725 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:672)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:456)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:01,741 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:01,741 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:01,741 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:01
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:01,741 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:01,741 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:01,741 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:01,741 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:01,741 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:01,741 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:01,741 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:01,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:01,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:01,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:07:01,756 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:01,756 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:01,756 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:01,756 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:01,756 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:01,756 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:01,756 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:01,756 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:01,756 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:01,772 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:01,772 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current
2017-10-16 13:07:01,772 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000007, cpktTxId=0000000000000000007)
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 2 INodes.
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.deflate]
2017-10-16 13:07:01,788 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:01,788 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 7 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000007
2017-10-16 13:07:01,788 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@2274160 expecting start txid #8
2017-10-16 13:07:01,788 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000008-0000000000000000009
2017-10-16 13:07:01,788 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000008-0000000000000000009' to transaction ID 8
2017-10-16 13:07:01,788 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000008-0000000000000000009 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:01,788 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:01,788 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 10
2017-10-16 13:07:01,850 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:01,850 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 95 msecs
2017-10-16 13:07:01,850 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to localhost:56007
2017-10-16 13:07:01,850 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:01,850 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56007
2017-10-16 13:07:01,850 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:01,850 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:120)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1058)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:679)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:665)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:456)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:01,866 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:01,866 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:01,866 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:01,866 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:01,866 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:01,866 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:01,866 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:01,866 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:01,881 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:01,881 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:01,881 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:01,881 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:01,881 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:01,881 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-10-16 13:07:01,881 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:01,881 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56007: starting
2017-10-16 13:07:01,881 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: localhost/127.0.0.1:56007
2017-10-16 13:07:01,881 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:01,881 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:01,881 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode is ON. 
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2017-10-16 13:07:01,881 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:07:01,881 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 10
2017-10-16 13:07:01,881 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:01,881 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000010 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000010-0000000000000000011
2017-10-16 13:07:01,881 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000011 using codec org.apache.hadoop.io.compress.GzipCodec
2017-10-16 13:07:01,881 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,881 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,881 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,881 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  compress.CodecPool (CodecPool.java:getCompressor(153)) - Got brand-new compressor [.gz]
2017-10-16 13:07:01,897 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000011 of size 662 bytes saved in 0 seconds.
2017-10-16 13:07:01,944 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 7
2017-10-16 13:07:01,944 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000003, cpktTxId=0000000000000000003)
2017-10-16 13:07:01,960 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 12
2017-10-16 13:07:02,006 INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(5010)) - New namespace image has been created
2017-10-16 13:07:02,006 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:02,006 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 12
2017-10-16 13:07:02,006 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:02,006 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:02,006 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:02,006 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000012 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000012-0000000000000000013
2017-10-16 13:07:02,006 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:02,006 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56007
2017-10-16 13:07:02,006 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56007
2017-10-16 13:07:02,006 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:02,006 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:02,022 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:02,022 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:02,022 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:02,131 INFO  namenode.TestStartup (TestStartup.java:testCompression(459)) - Read a compressed image and store it as uncompressed.
2017-10-16 13:07:02,131 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://localhost:56007
2017-10-16 13:07:02,131 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use localhost:56007 to access this namenode/service.
2017-10-16 13:07:02,131 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:56004
2017-10-16 13:07:06,647 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:06,647 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:06,647 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56004
2017-10-16 13:07:06,647 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:06,741 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:06,741 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:616)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:461)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:06,741 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:06,741 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:618)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:461)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:06,757 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:06,757 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:06,757 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:06,757 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:671)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:461)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:06,757 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:06,757 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:672)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:461)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:06,772 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:06,772 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:06,772 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:06
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:06,772 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:06,772 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:06,772 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:06,772 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:06,772 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:06,772 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:06,772 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:06,788 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:06,788 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:06,788 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:07:06,788 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:06,788 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:06,788 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:06,788 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:06,788 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:06,788 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:06,788 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:06,788 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:06,788 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:06,788 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:06,788 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current
2017-10-16 13:07:06,803 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 2 INodes.
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  compress.CodecPool (CodecPool.java:getDecompressor(181)) - Got brand-new decompressor [.gz]
2017-10-16 13:07:06,803 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:06,803 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 11 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000011
2017-10-16 13:07:06,803 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@3ce443f9 expecting start txid #12
2017-10-16 13:07:06,803 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000012-0000000000000000013
2017-10-16 13:07:06,803 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000012-0000000000000000013' to transaction ID 12
2017-10-16 13:07:06,803 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000012-0000000000000000013 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:06,803 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:06,803 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 14
2017-10-16 13:07:06,866 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:06,866 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 81 msecs
2017-10-16 13:07:06,866 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to localhost:56007
2017-10-16 13:07:06,866 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:06,866 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56007
2017-10-16 13:07:06,866 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:06,866 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:120)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1058)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:679)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:665)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:461)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:06,882 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:06,882 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:06,882 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:06,882 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:06,882 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:06,882 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:06,882 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:06,882 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:06,897 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:06,897 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:06,897 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:06,897 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:06,897 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:06,897 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 13 msec
2017-10-16 13:07:06,897 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:06,897 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56007: starting
2017-10-16 13:07:06,897 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: localhost/127.0.0.1:56007
2017-10-16 13:07:06,897 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:06,897 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:06,897 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode is ON. 
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2017-10-16 13:07:06,897 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:07:06,897 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 14
2017-10-16 13:07:06,897 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:06,897 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000014 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000014-0000000000000000015
2017-10-16 13:07:06,897 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000015 using no compression
2017-10-16 13:07:06,897 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000015 of size 441 bytes saved in 0 seconds.
2017-10-16 13:07:06,975 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 11
2017-10-16 13:07:06,975 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000007, cpktTxId=0000000000000000007)
2017-10-16 13:07:06,991 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 16
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(5010)) - New namespace image has been created
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:07,038 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 16
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:07,038 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:07,038 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000016 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000016-0000000000000000017
2017-10-16 13:07:07,038 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:07,038 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56007
2017-10-16 13:07:07,038 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56007
2017-10-16 13:07:07,038 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:07,038 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:07,038 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:07,038 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:07,147 INFO  namenode.TestStartup (TestStartup.java:testCompression(464)) - Read an uncompressed image and store it as uncompressed.
2017-10-16 13:07:07,147 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://localhost:56007
2017-10-16 13:07:07,147 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use localhost:56007 to access this namenode/service.
2017-10-16 13:07:07,147 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:56004
2017-10-16 13:07:11,690 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:11,690 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:11,691 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56004
2017-10-16 13:07:11,691 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:11,748 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:11,749 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:616)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:11,749 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:11,750 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkConfiguration(FSNamesystem.java:618)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:11,752 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:11,752 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:11,752 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:11,752 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceDirs(FSNamesystem.java:1355)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:671)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:11,752 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:11,752 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:672)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:585)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:645)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:11,753 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:11,753 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:11,753 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:11,753 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:11,753 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:11,753 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:11,753 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:11
2017-10-16 13:07:11,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:11,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:11,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:11,754 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 3
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:11,756 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:11,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:11,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:11,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = false
2017-10-16 13:07:11,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:11,756 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:11,757 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:11,757 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:11,757 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:11,757 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:11,758 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:11,758 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:11,758 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:11,758 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:11,758 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:11,758 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:11,758 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:11,758 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:11,759 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:11,759 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:11,759 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 30000
2017-10-16 13:07:11,759 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:11,759 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:11,759 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:11,759 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:11,759 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:11,761 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:11,761 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:11,761 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:11,761 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:11,762 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:11,763 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current
2017-10-16 13:07:11,763 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000015, cpktTxId=0000000000000000015)
2017-10-16 13:07:11,764 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 2 INodes.
2017-10-16 13:07:11,764 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:11,764 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 15 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000015
2017-10-16 13:07:11,764 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5b5ac798 expecting start txid #16
2017-10-16 13:07:11,764 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000016-0000000000000000017
2017-10-16 13:07:11,764 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000016-0000000000000000017' to transaction ID 16
2017-10-16 13:07:11,765 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000016-0000000000000000017 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:11,765 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:11,765 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 18
2017-10-16 13:07:11,812 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:11,812 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 50 msecs
2017-10-16 13:07:11,812 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to localhost:56007
2017-10-16 13:07:11,813 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:11,814 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56007
2017-10-16 13:07:11,815 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:11,815 ERROR common.Util (Util.java:stringAsURI(50)) - Syntax error in URI K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name. Please check hdfs configuration.
java.net.URISyntaxException: Illegal character in opaque part at index 2: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name
	at java.net.URI$Parser.fail(URI.java:2848)
	at java.net.URI$Parser.checkChars(URI.java:3021)
	at java.net.URI$Parser.parse(URI.java:3058)
	at java.net.URI.<init>(URI.java:588)
	at org.apache.hadoop.hdfs.server.common.Util.stringAsURI(Util.java:48)
	at org.apache.hadoop.hdfs.server.common.Util.stringCollectionAsURIs(Util.java:98)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getStorageDirs(FSNamesystem.java:1400)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1445)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getNamespaceEditsDirs(FSNamesystem.java:1414)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeResourceChecker.<init>(NameNodeResourceChecker.java:120)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1058)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:679)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:665)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:812)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:796)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameSpace(TestStartup.java:469)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testCompression(TestStartup.java:465)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)
	at com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)
	at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)
	at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)
2017-10-16 13:07:11,816 WARN  common.Util (Util.java:stringAsURI(56)) - Path K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name should be specified as a URI in configuration files. Please update hdfs configuration.
2017-10-16 13:07:11,817 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:11,817 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:11,817 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:11,817 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:11,817 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:11,817 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:11,817 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:11,833 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:11,833 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:11,833 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:11,833 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:11,833 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:11,833 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2017-10-16 13:07:11,833 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:11,833 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56007: starting
2017-10-16 13:07:11,833 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: localhost/127.0.0.1:56007
2017-10-16 13:07:11,833 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:11,833 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:11,833 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode is ON. 
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2017-10-16 13:07:11,833 INFO  namenode.FSImage (FSImage.java:saveNamespace(1096)) - Save namespace ...
2017-10-16 13:07:11,833 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 18
2017-10-16 13:07:11,833 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 1 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:11,833 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000018 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000018-0000000000000000019
2017-10-16 13:07:11,833 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000019 using no compression
2017-10-16 13:07:11,833 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage.ckpt_0000000000000000019 of size 441 bytes saved in 0 seconds.
2017-10-16 13:07:11,880 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 15
2017-10-16 13:07:11,880 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\fsimage_0000000000000000011, cpktTxId=0000000000000000011)
2017-10-16 13:07:11,895 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 20
2017-10-16 13:07:11,942 INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(5010)) - New namespace image has been created
2017-10-16 13:07:11,942 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:11,942 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 20
2017-10-16 13:07:11,942 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:11,942 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:11,942 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:07:11,942 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_inprogress_0000000000000000020 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\f5MQs4bPq3\TestStartup\dfs\name\current\edits_0000000000000000020-0000000000000000021
2017-10-16 13:07:11,942 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:11,942 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56007
2017-10-16 13:07:11,942 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56007
2017-10-16 13:07:11,942 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:11,942 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:11,958 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:11,958 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:11,958 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56004
2017-10-16 13:07:12,067 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:07:12,067 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(144)) - --starting mini cluster
2017-10-16 13:07:12,067 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:07:12,067 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:12,067 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:12,067 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:12,067 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:12,067 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:12,067 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:12
2017-10-16 13:07:12,067 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:12,067 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:12,067 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:12,067 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:12,067 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:12,067 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:12,067 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:12,083 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:12,083 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:12,083 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:12,083 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:12,083 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:12,083 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:12,083 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:12,083 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:12,083 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:12,083 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:12,083 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:12,083 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:12,083 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:12,083 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:12,083 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:12,145 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name has been successfully formatted.
2017-10-16 13:07:12,145 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:12,145 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:12,192 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:07:12,192 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:12,192 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(125)) - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2017-10-16 13:07:12,192 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(375)) - Scheduled snapshot period at 10 second(s).
2017-10-16 13:07:12,192 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(192)) - NameNode metrics system started
2017-10-16 13:07:12,192 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:07:12,192 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:07:16,718 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:16,718 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:16,718 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56047
2017-10-16 13:07:16,718 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:16,781 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56047
2017-10-16 13:07:16,781 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:16,781 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:16,781 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:16,781 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:16
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:16,781 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:16,781 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:16,781 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:16,796 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:16,796 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:16,796 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:16,796 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:16,796 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:16,796 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:16,796 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:16,796 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:16,796 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:16,796 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:16,796 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:16,796 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:16,796 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:16,812 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:16,812 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current
2017-10-16 13:07:16,812 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:07:16,812 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:16,812 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:16,812 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:16,812 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000
2017-10-16 13:07:16,812 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:16,812 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:07:16,859 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:16,859 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 73 msecs
2017-10-16 13:07:16,859 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:07:16,859 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:16,874 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56050
2017-10-16 13:07:16,874 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:56050 to access this namenode/service.
2017-10-16 13:07:16,874 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:16,874 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:16,874 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:16,874 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:16,874 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:16,874 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:16,874 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:16,874 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:16,906 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:16,906 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:16,906 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:16,906 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:16,906 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:16,906 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2017-10-16 13:07:16,906 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:16,906 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56050: starting
2017-10-16 13:07:16,906 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56050
2017-10-16 13:07:16,906 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:16,906 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:16,906 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:16,906 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:07:16,906 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:07:16,906 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:07:16,906 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:07:16,906 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:56057
2017-10-16 13:07:16,906 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:07:16,906 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:07:16,906 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:16,906 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:07:16,906 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:16,921 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:07:16,921 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:16,921 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:16,921 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56058
2017-10-16 13:07:16,921 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:16,984 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:56058
2017-10-16 13:07:16,999 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:56125
2017-10-16 13:07:16,999 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:07:16,999 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:07:16,999 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:16,999 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56126
2017-10-16 13:07:16,999 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:56126
2017-10-16 13:07:16,999 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:07:16,999 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:07:16,999 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:56050 starting to offer service
2017-10-16 13:07:16,999 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:16,999 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56126: starting
2017-10-16 13:07:16,999 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:07:16,999 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:16,999 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:17,015 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:17,015 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data is not formatted for namespace 1797740307. Formatting...
2017-10-16 13:07:17,015 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:17,077 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:17,077 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:17,077 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1014594029-192.168.232.1-1508173632083 is not formatted for BP-1014594029-192.168.232.1-1508173632083. Formatting ...
2017-10-16 13:07:17,077 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1014594029-192.168.232.1-1508173632083 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1014594029-192.168.232.1-1508173632083\current
2017-10-16 13:07:17,109 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:17,109 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:17,140 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1797740307;bpid=BP-1014594029-192.168.232.1-1508173632083;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1797740307;c=0;bpid=BP-1014594029-192.168.232.1-1508173632083;dnuuid=null
2017-10-16 13:07:17,171 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID bee3c596-5791-423a-97f0-54ffad06b385
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1014594029-192.168.232.1-1508173632083 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 2ms
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1014594029-192.168.232.1-1508173632083: 2ms
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 0ms
2017-10-16 13:07:17,171 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:07:17,171 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:17,171 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508193112171 with interval 21600000
2017-10-16 13:07:17,171 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3): finished scanning block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:17,171 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56050 beginning handshake with NN
2017-10-16 13:07:17,171 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:56057, datanodeUuid=bee3c596-5791-423a-97f0-54ffad06b385, infoPort=56125, infoSecurePort=0, ipcPort=56126, storageInfo=lv=-56;cid=testClusterID;nsid=1797740307;c=0) storage bee3c596-5791-423a-97f0-54ffad06b385
2017-10-16 13:07:17,171 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:17,171 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3): no suitable block pools found to scan.  Waiting 1814400000 ms.
2017-10-16 13:07:17,171 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:56057
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56050 successfully registered with NN
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:56050 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:07:17,187 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:17,187 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3 for DN 127.0.0.1:56057
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56050 trying to claim ACTIVE state with txid=1
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56050
2017-10-16 13:07:17,187 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3 node DatanodeRegistration(127.0.0.1:56057, datanodeUuid=bee3c596-5791-423a-97f0-54ffad06b385, infoPort=56125, infoSecurePort=0, ipcPort=56126, storageInfo=lv=-56;cid=testClusterID;nsid=1797740307;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa35613d0e8d2f,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:07:17,187 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:17,218 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:17,218 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:17,218 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(155)) - --starting Secondary Node
2017-10-16 13:07:17,218 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - SecondaryNameNode metrics system started (again)
2017-10-16 13:07:17,234 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:17,234 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:17,234 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:17,234 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:17,234 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:17,234 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:17,234 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:17
2017-10-16 13:07:17,234 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:17,234 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:17,234 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:17,234 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:17,312 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:17,312 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:17,312 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:17,312 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:17,312 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:17,312 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:17,312 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:17,312 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:17,312 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:17,312 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:17,312 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for secondary at: http://0.0.0.0:0
2017-10-16 13:07:21,852 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:21,852 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.secondary is not defined
2017-10-16 13:07:21,852 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:21,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2017-10-16 13:07:21,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:21,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:21,852 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56138
2017-10-16 13:07:21,852 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:21,899 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:56138
2017-10-16 13:07:21,899 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(278)) - Web server init done
2017-10-16 13:07:21,899 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(297)) - Checkpoint Period   :3600 secs (60 min)
2017-10-16 13:07:21,899 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(299)) - Log Size Trigger    :1000000 txns
2017-10-16 13:07:21,899 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/Zhibin/t0	dst=null	perm=Zhibin:supergroup:rw-r--r--	proto=rpc
2017-10-16 13:07:21,899 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} for /user/Zhibin/t0
2017-10-16 13:07:21,899 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1014594029-192.168.232.1-1508173632083:blk_1073741825_1001 src: /127.0.0.1:56141 dest: /127.0.0.1:56057
2017-10-16 13:07:21,914 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:56141, dest: /127.0.0.1:56057, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1922079742_841, offset: 0, srvID: bee3c596-5791-423a-97f0-54ffad06b385, blockid: BP-1014594029-192.168.232.1-1508173632083:blk_1073741825_1001, duration: 1829878
2017-10-16 13:07:21,914 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1014594029-192.168.232.1-1508173632083:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:07:21,914 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:56057 is added to blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} size 0
2017-10-16 13:07:21,914 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} for /user/Zhibin/t0
2017-10-16 13:07:21,914 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1014594029-192.168.232.1-1508173632083:blk_1073741826_1002 src: /127.0.0.1:56142 dest: /127.0.0.1:56057
2017-10-16 13:07:21,914 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:56142, dest: /127.0.0.1:56057, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1922079742_841, offset: 0, srvID: bee3c596-5791-423a-97f0-54ffad06b385, blockid: BP-1014594029-192.168.232.1-1508173632083:blk_1073741826_1002, duration: 1263588
2017-10-16 13:07:21,914 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1014594029-192.168.232.1-1508173632083:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:07:21,914 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:56057 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} size 0
2017-10-16 13:07:21,914 INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3494)) - DIR* completeFile: /user/Zhibin/t0 is closed by DFSClient_NONMAPREDUCE_-1922079742_841
2017-10-16 13:07:21,914 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(167)) - --file t0 created
2017-10-16 13:07:21,914 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(168)) - --doing checkpoint
2017-10-16 13:07:21,914 INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(5834)) - Roll Edit Log from 127.0.0.1
2017-10-16 13:07:21,914 INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1202)) - Rolling edit logs
2017-10-16 13:07:21,914 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:07:21,914 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 12 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 7 SyncTimes(ms): 1 
2017-10-16 13:07:21,914 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:07:21,914 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 13
2017-10-16 13:07:21,961 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(455)) - Image has changed. Downloading updated image from NN.
2017-10-16 13:07:21,961 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:56047/imagetransfer?getimage=1&txid=0&storageInfo=-63:1797740307:0:testClusterID
2017-10-16 13:07:22,008 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.05s at 0.00 KB/s
2017-10-16 13:07:22,008 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(115)) - Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2017-10-16 13:07:22,055 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:56047/imagetransfer?getedit=1&startTxId=1&endTxId=12&storageInfo=-63:1797740307:0:testClusterID
2017-10-16 13:07:22,071 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.02s at 0.00 KB/s
2017-10-16 13:07:22,071 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(168)) - Downloaded file edits_tmp_0000000000000000001-0000000000000000012_0000000002873446380 size 0 bytes.
2017-10-16 13:07:22,086 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:22,086 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:22,086 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage_0000000000000000000
2017-10-16 13:07:22,086 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:22,086 INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(309)) - Checkpointer about to load edits from 1 stream(s).
2017-10-16 13:07:22,086 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000001-0000000000000000012 expecting start txid #1
2017-10-16 13:07:22,086 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000001-0000000000000000012
2017-10-16 13:07:22,086 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000001-0000000000000000012 of size 727 edits # 12 loaded in 0 seconds
2017-10-16 13:07:22,086 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage.ckpt_0000000000000000012 using no compression
2017-10-16 13:07:22,102 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage.ckpt_0000000000000000012 of size 576 bytes saved in 0 seconds.
2017-10-16 13:07:22,149 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary
2017-10-16 13:07:22,227 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.06s at 0.00 KB/s
2017-10-16 13:07:22,227 INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(134)) - Downloaded file fsimage.ckpt_0000000000000000012 size 576 bytes.
2017-10-16 13:07:22,258 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2017-10-16 13:07:22,258 INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(237)) - Uploaded image with txid 12 to namenode at http://lambda-pluralsight:56047 in 0.11 seconds
2017-10-16 13:07:22,274 WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(566)) - Checkpoint done. New Image Size: 576
2017-10-16 13:07:22,274 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(170)) - --done checkpoint
2017-10-16 13:07:22,274 INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(8256)) - allowed=true	ugi=Zhibin (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/Zhibin/t1	dst=null	perm=Zhibin:supergroup:rw-r--r--	proto=rpc
2017-10-16 13:07:22,274 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} for /user/Zhibin/t1
2017-10-16 13:07:22,274 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1014594029-192.168.232.1-1508173632083:blk_1073741827_1003 src: /127.0.0.1:56145 dest: /127.0.0.1:56057
2017-10-16 13:07:22,274 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:56145, dest: /127.0.0.1:56057, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1922079742_841, offset: 0, srvID: bee3c596-5791-423a-97f0-54ffad06b385, blockid: BP-1014594029-192.168.232.1-1508173632083:blk_1073741827_1003, duration: 1865800
2017-10-16 13:07:22,274 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1014594029-192.168.232.1-1508173632083:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:07:22,274 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:56057 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} size 0
2017-10-16 13:07:22,274 INFO  hdfs.StateChange (FSNamesystem.java:saveAllocatedBlock(3574)) - BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} for /user/Zhibin/t1
2017-10-16 13:07:22,274 INFO  datanode.DataNode (DataXceiver.java:writeBlock(660)) - Receiving BP-1014594029-192.168.232.1-1508173632083:blk_1073741828_1004 src: /127.0.0.1:56146 dest: /127.0.0.1:56057
2017-10-16 13:07:22,289 INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1434)) - src: /127.0.0.1:56146, dest: /127.0.0.1:56057, bytes: 4096, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1922079742_841, offset: 0, srvID: bee3c596-5791-423a-97f0-54ffad06b385, blockid: BP-1014594029-192.168.232.1-1508173632083:blk_1073741828_1004, duration: 2074386
2017-10-16 13:07:22,289 INFO  datanode.DataNode (BlockReceiver.java:run(1407)) - PacketResponder: BP-1014594029-192.168.232.1-1508173632083:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2017-10-16 13:07:22,289 INFO  namenode.FSNamesystem (FSNamesystem.java:isCompleteBlock(3618)) - BLOCK* blk_1073741828_1004{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /user/Zhibin/t1
2017-10-16 13:07:22,289 INFO  namenode.EditLogFileOutputStream (EditLogFileOutputStream.java:flushAndSync(200)) - Nothing to flush
2017-10-16 13:07:22,289 INFO  BlockStateChange (BlockManager.java:logAddStoredBlock(2645)) - BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:56057 is added to blk_1073741828_1004{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3:NORMAL:127.0.0.1:56057|RBW]]} size 4096
2017-10-16 13:07:22,696 INFO  hdfs.StateChange (FSNamesystem.java:completeFile(3494)) - DIR* completeFile: /user/Zhibin/t1 is closed by DFSClient_NONMAPREDUCE_-1922079742_841
2017-10-16 13:07:22,696 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(167)) - --file t1 created
2017-10-16 13:07:22,696 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(168)) - --doing checkpoint
2017-10-16 13:07:22,696 INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(5834)) - Roll Edit Log from 127.0.0.1
2017-10-16 13:07:22,696 INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1202)) - Rolling edit logs
2017-10-16 13:07:22,696 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 13
2017-10-16 13:07:22,696 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 10 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 0 Number of syncs: 8 SyncTimes(ms): 0 
2017-10-16 13:07:22,696 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000013 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000013-0000000000000000022
2017-10-16 13:07:22,696 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 23
2017-10-16 13:07:22,727 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(453)) - Image has not changed. Will not download image.
2017-10-16 13:07:22,727 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:56047/imagetransfer?getedit=1&startTxId=13&endTxId=22&storageInfo=-63:1797740307:0:testClusterID
2017-10-16 13:07:22,774 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.04s at 0.00 KB/s
2017-10-16 13:07:22,774 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(168)) - Downloaded file edits_tmp_0000000000000000013-0000000000000000022_0000000002873447066 size 0 bytes.
2017-10-16 13:07:22,789 INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(309)) - Checkpointer about to load edits from 1 stream(s).
2017-10-16 13:07:22,789 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000013-0000000000000000022 expecting start txid #13
2017-10-16 13:07:22,789 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000013-0000000000000000022
2017-10-16 13:07:22,789 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\edits_0000000000000000013-0000000000000000022 of size 574 edits # 10 loaded in 0 seconds
2017-10-16 13:07:22,789 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage.ckpt_0000000000000000022 using no compression
2017-10-16 13:07:22,805 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage.ckpt_0000000000000000022 of size 650 bytes saved in 0 seconds.
2017-10-16 13:07:22,836 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 12
2017-10-16 13:07:22,836 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\secondary\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:22,899 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.05s at 0.00 KB/s
2017-10-16 13:07:22,899 INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(134)) - Downloaded file fsimage.ckpt_0000000000000000022 size 650 bytes.
2017-10-16 13:07:22,946 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 12
2017-10-16 13:07:22,946 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:22,946 INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(237)) - Uploaded image with txid 22 to namenode at http://lambda-pluralsight:56047 in 0.097 seconds
2017-10-16 13:07:22,946 WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(566)) - Checkpoint done. New Image Size: 650
2017-10-16 13:07:22,946 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(170)) - --done checkpoint
2017-10-16 13:07:22,946 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:0
2017-10-16 13:07:23,055 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:23,055 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:07:23,055 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:07:23,055 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:07:23,055 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3) exiting.
2017-10-16 13:07:23,055 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56126
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56126
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:23,164 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56050 interrupted
2017-10-16 13:07:23,164 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56050
2017-10-16 13:07:23,164 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385)
2017-10-16 13:07:23,164 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:23,164 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:07:23,164 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:07:23,164 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:07:23,164 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:07:23,164 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:07:23,164 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:07:23,164 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:23,164 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 23
2017-10-16 13:07:23,164 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:23,164 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:23,164 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 
2017-10-16 13:07:23,164 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000023 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000023-0000000000000000024
2017-10-16 13:07:23,164 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56050
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56050
2017-10-16 13:07:23,164 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:23,164 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:23,164 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:23,164 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:23,180 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:07:23,289 INFO  namenode.TestStartup (TestStartup.java:createCheckPoint(181)) - --cluster shutdown
2017-10-16 13:07:23,368 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
2017-10-16 13:07:23,368 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:23,368 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:07:23,368 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:07:23,368 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:07:27,892 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:27,892 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:27,892 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56147
2017-10-16 13:07:27,892 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:27,954 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56147
2017-10-16 13:07:27,954 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:27,954 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:27,954 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:27,954 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:27
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:27,954 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:27,954 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:27,954 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:27,954 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:27,970 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:27,970 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:27,970 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:27,970 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:27,970 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:27,970 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:27,970 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:27,970 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:27,970 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:27,970 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:27,970 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:27,970 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:27,970 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:27,970 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current
2017-10-16 13:07:27,970 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000022, cpktTxId=0000000000000000022)
2017-10-16 13:07:27,970 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 5 INodes.
2017-10-16 13:07:27,970 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:27,970 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 22 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000022
2017-10-16 13:07:27,970 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@780f5443 expecting start txid #23
2017-10-16 13:07:27,970 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000023-0000000000000000024
2017-10-16 13:07:27,970 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000023-0000000000000000024' to transaction ID 23
2017-10-16 13:07:27,986 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000023-0000000000000000024 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:27,986 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:27,986 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 25
2017-10-16 13:07:28,017 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:28,017 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 59 msecs
2017-10-16 13:07:28,017 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:07:28,017 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:28,032 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56150
2017-10-16 13:07:28,032 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:56150 to access this namenode/service.
2017-10-16 13:07:28,032 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:28,032 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:28,032 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:28,032 INFO  hdfs.StateChange (FSNamesystem.java:reportStatus(5513)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 4 blocks to reach the threshold 0.9990 of total blocks 4.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2017-10-16 13:07:28,032 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:28,032 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:28,032 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56150: starting
2017-10-16 13:07:28,032 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56150
2017-10-16 13:07:28,032 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:28,032 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:28,032 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:28,064 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:07:28,064 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:07:28,064 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:07:28,064 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:07:28,064 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:56157
2017-10-16 13:07:28,064 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:07:28,064 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:07:28,064 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:28,064 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:07:28,064 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:28,064 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:07:28,064 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:28,064 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:28,064 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56158
2017-10-16 13:07:28,064 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:28,126 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:56158
2017-10-16 13:07:28,142 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:56225
2017-10-16 13:07:28,142 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:07:28,142 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:07:28,142 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:28,142 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56226
2017-10-16 13:07:28,142 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:56226
2017-10-16 13:07:28,142 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:07:28,142 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:07:28,142 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:56150 starting to offer service
2017-10-16 13:07:28,142 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56226: starting
2017-10-16 13:07:28,142 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:28,142 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:28,142 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:28,142 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:07:28,142 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:28,173 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:28,173 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:28,189 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1797740307;bpid=BP-1014594029-192.168.232.1-1508173632083;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1797740307;c=0;bpid=BP-1014594029-192.168.232.1-1508173632083;dnuuid=bee3c596-5791-423a-97f0-54ffad06b385
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(221)) - Cached dfsUsed found for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1014594029-192.168.232.1-1508173632083\current: 16678
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1014594029-192.168.232.1-1508173632083 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 1ms
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1014594029-192.168.232.1-1508173632083: 2ms
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1014594029-192.168.232.1-1508173632083 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 1ms
2017-10-16 13:07:28,189 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:07:28,189 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3): no suitable block pools found to scan.  Waiting 1814388982 ms.
2017-10-16 13:07:28,189 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508192883189 with interval 21600000
2017-10-16 13:07:28,189 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56150 beginning handshake with NN
2017-10-16 13:07:28,204 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:56157, datanodeUuid=bee3c596-5791-423a-97f0-54ffad06b385, infoPort=56225, infoSecurePort=0, ipcPort=56226, storageInfo=lv=-56;cid=testClusterID;nsid=1797740307;c=0) storage bee3c596-5791-423a-97f0-54ffad06b385
2017-10-16 13:07:28,204 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:28,204 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:56157
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56150 successfully registered with NN
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:56150 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:07:28,204 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:28,204 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3 for DN 127.0.0.1:56157
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56150 trying to claim ACTIVE state with txid=25
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56150
2017-10-16 13:07:28,204 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:28,204 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:28,204 INFO  hdfs.StateChange (FSNamesystem.java:leave(5251)) - STATE* Safe mode is OFF
2017-10-16 13:07:28,204 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 1 racks and 1 datanodes
2017-10-16 13:07:28,204 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:28,204 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3 node DatanodeRegistration(127.0.0.1:56157, datanodeUuid=bee3c596-5791-423a-97f0-54ffad06b385, infoPort=56225, infoSecurePort=0, ipcPort=56226, storageInfo=lv=-56;cid=testClusterID;nsid=1797740307;c=0), blocks: 4, hasStaleStorage: false, processing time: 1 msecs
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa3563cd876778,  containing 1 storage report(s), of which we sent 1. The reports had 4 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:07:28,204 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:28,204 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 4
2017-10-16 13:07:28,204 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:28,204 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:28,220 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:28,220 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:28,220 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2017-10-16 13:07:28,251 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:28,251 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:28,251 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:28,251 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:07:28,251 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:07:28,251 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:07:28,251 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-29f7572e-50fd-4fe7-bd55-313d5b9b43d3) exiting.
2017-10-16 13:07:28,267 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:07:28,376 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56226
2017-10-16 13:07:28,376 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56226
2017-10-16 13:07:28,376 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:28,376 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56150 interrupted
2017-10-16 13:07:28,376 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385) service to lambda-pluralsight/127.0.0.1:56150
2017-10-16 13:07:28,376 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1014594029-192.168.232.1-1508173632083 (Datanode Uuid bee3c596-5791-423a-97f0-54ffad06b385)
2017-10-16 13:07:28,376 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1014594029-192.168.232.1-1508173632083
2017-10-16 13:07:28,392 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:07:28,392 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:07:28,392 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:07:28,392 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:07:28,392 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:07:28,392 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:07:28,392 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:28,392 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 25
2017-10-16 13:07:28,392 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:28,392 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:28,392 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:07:28,392 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000025 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000025-0000000000000000026
2017-10-16 13:07:28,392 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:28,392 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56150
2017-10-16 13:07:28,392 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56150
2017-10-16 13:07:28,392 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:28,392 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:28,407 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:28,407 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:28,423 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:07:28,595 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:07:28,611 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(361)) - --starting SecondNN startup test
2017-10-16 13:07:28,611 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(373)) - --starting NN 
2017-10-16 13:07:28,611 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:28,611 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:28,611 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:28
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:28,611 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:28,611 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:28,611 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:28,611 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:28,611 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:28,611 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:28,626 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:28,626 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:28,626 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:28,626 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:28,626 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:28,626 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:28,626 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:28,626 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:28,626 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:28,626 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:28,626 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:28,689 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name has been successfully formatted.
2017-10-16 13:07:28,689 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:28,704 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:28,830 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:07:28,830 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:28,830 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:07:28,830 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:07:28,846 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:07:33,370 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:33,370 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:33,370 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56235
2017-10-16 13:07:33,370 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:33,442 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56235
2017-10-16 13:07:33,442 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(647)) - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:33,442 WARN  namenode.FSNamesystem (FSNamesystem.java:checkConfiguration(652)) - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:33,442 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:33,442 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:33
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:33,442 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:33,442 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:33,442 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:33,458 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:33,458 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:33,458 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:33,458 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:33,458 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:33,458 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:33,458 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:33,458 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:33,458 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:33,458 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:33,458 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:33,458 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:33,458 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:33,458 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:33,474 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current
2017-10-16 13:07:33,474 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:07:33,474 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:33,475 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:33,475 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:33,475 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000
2017-10-16 13:07:33,475 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:33,475 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:07:33,531 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:33,531 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 71 msecs
2017-10-16 13:07:33,532 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:07:33,532 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:33,535 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56238
2017-10-16 13:07:33,537 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:56238 to access this namenode/service.
2017-10-16 13:07:33,538 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:33,540 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:33,540 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:33,540 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:33,540 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:33,541 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:33,541 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:33,541 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:33,550 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:33,550 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:33,550 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:33,550 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:33,550 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:33,551 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2017-10-16 13:07:33,552 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:33,553 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56238: starting
2017-10-16 13:07:33,554 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56238
2017-10-16 13:07:33,554 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:33,556 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:33,556 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:33,559 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:07:33,559 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:07:33,560 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:07:33,560 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:07:33,561 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:56245
2017-10-16 13:07:33,561 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:07:33,561 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:07:33,563 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:33,564 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:07:33,565 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:33,566 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:07:33,566 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:33,566 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:33,567 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56246
2017-10-16 13:07:33,567 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:33,786 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:56246
2017-10-16 13:07:33,796 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:56313
2017-10-16 13:07:33,796 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:07:33,796 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:07:33,797 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:33,798 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56314
2017-10-16 13:07:33,799 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:56314
2017-10-16 13:07:33,800 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:07:33,800 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:07:33,801 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:56238 starting to offer service
2017-10-16 13:07:33,801 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:33,801 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56314: starting
2017-10-16 13:07:33,804 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:33,805 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:33,805 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2017-10-16 13:07:33,814 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:33,814 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data is not formatted for namespace 671674970. Formatting...
2017-10-16 13:07:33,815 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:33,872 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:33,873 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:33,873 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1565296694-192.168.232.1-1508173648626 is not formatted for BP-1565296694-192.168.232.1-1508173648626. Formatting ...
2017-10-16 13:07:33,873 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1565296694-192.168.232.1-1508173648626 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current\BP-1565296694-192.168.232.1-1508173648626\current
2017-10-16 13:07:33,907 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:33,907 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:33,928 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=671674970;bpid=BP-1565296694-192.168.232.1-1508173648626;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=671674970;c=0;bpid=BP-1565296694-192.168.232.1-1508173648626;dnuuid=null
2017-10-16 13:07:34,006 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID e1732a6d-a68e-4a92-a300-c930fd82303c
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current, StorageType: DISK
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1565296694-192.168.232.1-1508173648626 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1565296694-192.168.232.1-1508173648626 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 1ms
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1565296694-192.168.232.1-1508173648626: 3ms
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1565296694-192.168.232.1-1508173648626 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current...
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1565296694-192.168.232.1-1508173648626 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\current: 0ms
2017-10-16 13:07:34,006 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 0ms
2017-10-16 13:07:34,006 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-1565296694-192.168.232.1-1508173648626 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data
2017-10-16 13:07:34,006 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508193895006 with interval 21600000
2017-10-16 13:07:34,006 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62): finished scanning block pool BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:34,006 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56238 beginning handshake with NN
2017-10-16 13:07:34,006 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:56245, datanodeUuid=e1732a6d-a68e-4a92-a300-c930fd82303c, infoPort=56313, infoSecurePort=0, ipcPort=56314, storageInfo=lv=-56;cid=testClusterID;nsid=671674970;c=0) storage e1732a6d-a68e-4a92-a300-c930fd82303c
2017-10-16 13:07:34,006 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:34,006 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:56245
2017-10-16 13:07:34,006 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62): no suitable block pools found to scan.  Waiting 1814400000 ms.
2017-10-16 13:07:34,006 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56238 successfully registered with NN
2017-10-16 13:07:34,021 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:56238 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:07:34,021 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2370)) - No heartbeat from DataNode: 127.0.0.1:56245
2017-10-16 13:07:34,021 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:34,021 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:34,021 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62 for DN 127.0.0.1:56245
2017-10-16 13:07:34,021 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid e1732a6d-a68e-4a92-a300-c930fd82303c) service to lambda-pluralsight/127.0.0.1:56238 trying to claim ACTIVE state with txid=1
2017-10-16 13:07:34,021 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid e1732a6d-a68e-4a92-a300-c930fd82303c) service to lambda-pluralsight/127.0.0.1:56238
2017-10-16 13:07:34,021 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62 node DatanodeRegistration(127.0.0.1:56245, datanodeUuid=e1732a6d-a68e-4a92-a300-c930fd82303c, infoPort=56313, infoSecurePort=0, ipcPort=56314, storageInfo=lv=-56;cid=testClusterID;nsid=671674970;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:07:34,021 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa3565288be093,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:07:34,021 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:34,131 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:34,131 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:34,131 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(386)) - --starting SecondNN
2017-10-16 13:07:34,131 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - SecondaryNameNode metrics system started (again)
2017-10-16 13:07:34,177 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:34,302 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:34,302 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:34,302 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:34
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:34,302 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:34,302 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:34,302 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:34,302 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:34,302 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:34,302 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:34,302 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:34,318 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:34,318 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:34,318 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:34,318 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:34,318 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:34,318 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:34,318 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:34,318 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:34,318 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:34,318 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:34,318 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for secondary at: http://0.0.0.0:0
2017-10-16 13:07:38,852 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:38,852 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.secondary is not defined
2017-10-16 13:07:38,852 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:38,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
2017-10-16 13:07:38,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:38,852 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:38,852 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56323
2017-10-16 13:07:38,852 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:38,915 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:56323
2017-10-16 13:07:38,930 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(278)) - Web server init done
2017-10-16 13:07:38,930 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(297)) - Checkpoint Period   :3600 secs (60 min)
2017-10-16 13:07:38,930 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:initialize(299)) - Log Size Trigger    :1000000 txns
2017-10-16 13:07:38,930 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(390)) - --doing checkpoint
2017-10-16 13:07:38,930 INFO  namenode.FSNamesystem (FSNamesystem.java:rollEditLog(5834)) - Roll Edit Log from 127.0.0.1
2017-10-16 13:07:38,930 INFO  namenode.FSEditLog (FSEditLog.java:rollEditLog(1202)) - Rolling edit logs
2017-10-16 13:07:38,930 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:07:38,930 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:07:38,930 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:38,930 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 3
2017-10-16 13:07:38,961 INFO  namenode.SecondaryNameNode (SecondaryNameNode.java:run(455)) - Image has changed. Downloading updated image from NN.
2017-10-16 13:07:38,961 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:56235/imagetransfer?getimage=1&txid=0&storageInfo=-63:671674970:0:testClusterID
2017-10-16 13:07:39,023 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.04s at 0.00 KB/s
2017-10-16 13:07:39,023 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadImageToStorage(115)) - Downloaded file fsimage.ckpt_0000000000000000000 size 353 bytes.
2017-10-16 13:07:39,055 INFO  namenode.TransferFsImage (TransferFsImage.java:getFileClient(396)) - Opening connection to http://lambda-pluralsight:56235/imagetransfer?getedit=1&startTxId=1&endTxId=2&storageInfo=-63:671674970:0:testClusterID
2017-10-16 13:07:39,102 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.04s at 0.00 KB/s
2017-10-16 13:07:39,102 INFO  namenode.TransferFsImage (TransferFsImage.java:downloadEditsToStorage(168)) - Downloaded file edits_tmp_0000000000000000001-0000000000000000002_0000000002873463391 size 0 bytes.
2017-10-16 13:07:39,117 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:39,117 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:39,117 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000000
2017-10-16 13:07:39,117 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:39,117 INFO  namenode.Checkpointer (Checkpointer.java:rollForwardByApplyingLogs(309)) - Checkpointer about to load edits from 1 stream(s).
2017-10-16 13:07:39,117 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000002 expecting start txid #1
2017-10-16 13:07:39,117 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:39,117 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:39,117 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000002 using no compression
2017-10-16 13:07:39,133 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage.ckpt_0000000000000000002 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:39,180 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt
2017-10-16 13:07:39,180 INFO  namenode.FSImageTransactionalStorageInspector (FSImageTransactionalStorageInspector.java:inspectDirectory(85)) - No version file in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits
2017-10-16 13:07:39,273 INFO  namenode.TransferFsImage (TransferFsImage.java:receiveFile(553)) - Transfer took 0.05s at 0.00 KB/s
2017-10-16 13:07:39,274 INFO  namenode.TransferFsImage (TransferFsImage.java:handleUploadImageRequest(134)) - Downloaded file fsimage.ckpt_0000000000000000002 size 353 bytes.
2017-10-16 13:07:39,315 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2017-10-16 13:07:39,315 INFO  namenode.TransferFsImage (TransferFsImage.java:uploadImageFromStorage(237)) - Uploaded image with txid 2 to namenode at http://lambda-pluralsight:56235 in 0.1 seconds
2017-10-16 13:07:39,315 WARN  namenode.SecondaryNameNode (SecondaryNameNode.java:doCheckpoint(566)) - Checkpoint done. New Image Size: 353
2017-10-16 13:07:39,315 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(392)) - --done checkpoint
2017-10-16 13:07:39,315 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(404)) - --image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\fsimage_0000000000000000000; len = 353
2017-10-16 13:07:39,315 INFO  namenode.TestStartup (TestStartup.java:testSNNStartup(405)) - --edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000000; len = 0
2017-10-16 13:07:39,315 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(289)) - --image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt\current\fsimage_0000000000000000000; len = 353; expected = 353
2017-10-16 13:07:39,315 INFO  namenode.TestStartup (TestStartup.java:verifyDifferentDirs(294)) - -- edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\chkpt_edits\current\edits_0000000000000000000; len = 0; expected = 0
2017-10-16 13:07:39,315 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:0
2017-10-16 13:07:39,424 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:39,424 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:07:39,424 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:07:39,424 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:07:39,424 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data, DS-7331cec6-ddf6-4a38-9d95-f7a5a555aa62) exiting.
2017-10-16 13:07:39,424 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:07:39,525 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56314
2017-10-16 13:07:39,526 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56314
2017-10-16 13:07:39,526 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:39,526 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid e1732a6d-a68e-4a92-a300-c930fd82303c) service to lambda-pluralsight/127.0.0.1:56238 interrupted
2017-10-16 13:07:39,526 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid e1732a6d-a68e-4a92-a300-c930fd82303c) service to lambda-pluralsight/127.0.0.1:56238
2017-10-16 13:07:39,526 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1565296694-192.168.232.1-1508173648626 (Datanode Uuid e1732a6d-a68e-4a92-a300-c930fd82303c)
2017-10-16 13:07:39,526 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1565296694-192.168.232.1-1508173648626
2017-10-16 13:07:39,526 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:07:39,526 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:07:39,526 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:07:39,526 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:07:39,526 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:07:39,526 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:07:39,526 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:39,526 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 3
2017-10-16 13:07:39,526 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:39,526 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:39,526 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 
2017-10-16 13:07:39,526 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_inprogress_0000000000000000003 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name\current\edits_0000000000000000003-0000000000000000004
2017-10-16 13:07:39,526 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:39,526 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56238
2017-10-16 13:07:39,526 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56238
2017-10-16 13:07:39,526 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:39,526 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:39,526 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:39,526 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:39,541 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:07:39,729 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:07:39,745 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2017-10-16 13:07:39,745 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:39,745 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:39,745 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:39,745 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:39,745 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:39,745 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:39
2017-10-16 13:07:39,745 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:39,745 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,745 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:39,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:39,760 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:39,760 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:39,760 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:39,760 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:39,760 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:39,760 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:39,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:39,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:39,760 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:39,760 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:39,760 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:39,760 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(851)) - FSNamesystem initialization failed.
java.lang.IllegalArgumentException: Cannot set a negative value for the maximum size of an xattr (dfs.namenode.fs-limits.max-xattr-size).
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:115)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:830)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:697)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:985)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:343)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:184)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:977)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testXattrConfiguration(TestStartup.java:653)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:39,776 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:39,776 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:39,776 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:39,776 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:39
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:39,776 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:39,776 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:39,776 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:39,776 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:39,791 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:39,791 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:39,791 ERROR namenode.FSNamesystem (FSNamesystem.java:<init>(851)) - FSNamesystem initialization failed.
java.lang.IllegalArgumentException: Cannot set a negative limit on the number of xattrs per inode (dfs.namenode.fs-limits.max-xattrs-per-inode).
	at com.google.common.base.Preconditions.checkArgument(Preconditions.java:115)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:283)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:830)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:697)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:985)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:343)
	at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:184)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:977)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:815)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:475)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:434)
	at org.apache.hadoop.hdfs.server.namenode.TestStartup.testXattrConfiguration(TestStartup.java:669)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2017-10-16 13:07:39,791 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:39,791 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:39,791 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:39,791 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2017-10-16 13:07:39,791 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:39,791 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:39,791 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:39,791 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:39,791 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:39,791 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:39
2017-10-16 13:07:39,791 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:39,791 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,791 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:39,791 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:39,791 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:39,791 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:39,807 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:39,807 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:39,807 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:39,807 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 0 (unlimited)
2017-10-16 13:07:39,807 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:39,807 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:39,807 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:39,807 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:39,807 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:39,807 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:39,807 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-2011865197-192.168.232.1-1508173659807
2017-10-16 13:07:39,885 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1 has been successfully formatted.
2017-10-16 13:07:39,948 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2 has been successfully formatted.
2017-10-16 13:07:39,948 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:39,948 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:39,963 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:39,979 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:40,042 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:07:40,042 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:40,042 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:07:40,042 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:07:40,042 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:07:44,593 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:44,593 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:44,593 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56329
2017-10-16 13:07:44,593 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:44,640 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56329
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:44,640 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:44,640 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:44
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 0
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:44,640 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:44,640 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:44,640 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:44,640 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:44,640 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 0 (unlimited)
2017-10-16 13:07:44,640 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:44,640 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:44,655 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:44,655 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:44,655 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:44,655 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:44,655 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:44,655 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:44,655 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:44,655 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:44,655 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:44,671 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:44,695 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:44,695 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:07:44,695 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:07:44,695 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:07:44,695 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:44,695 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:44,710 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:44,710 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:07:44,710 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:44,710 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:07:44,804 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:44,804 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 151 msecs
2017-10-16 13:07:44,804 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:07:44,804 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:44,804 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56332
2017-10-16 13:07:44,804 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:56332 to access this namenode/service.
2017-10-16 13:07:44,804 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:44,804 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:44,804 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:44,804 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:44,804 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:44,804 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:44,804 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:44,804 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:44,835 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2017-10-16 13:07:44,835 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56332: starting
2017-10-16 13:07:44,835 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:44,835 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56332
2017-10-16 13:07:44,835 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:44,835 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:44,835 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:44,835 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:44,835 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:44,835 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:07:44,835 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:44,835 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:44,835 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 0 
2017-10-16 13:07:44,835 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:44,835 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:44,835 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:44,835 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56332
2017-10-16 13:07:44,835 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56332
2017-10-16 13:07:44,835 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:44,835 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:44,851 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:44,851 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:44,851 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:07:44,986 INFO  namenode.TestStartup (TestStartup.java:setUp(112)) - --hdfsdir is K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs
2017-10-16 13:07:45,002 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(450)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:45,017 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:45,017 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:45
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:45,017 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:45,017 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:45,017 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:45,017 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:45,017 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:45,017 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:45,017 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:45,033 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:45,033 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:45,033 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:45,033 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:45,033 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:45,033 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:45,033 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:45,033 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:45,033 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:45,033 INFO  namenode.FSImage (FSImage.java:format(158)) - Allocated new BlockPoolId: BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:45,095 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1 has been successfully formatted.
2017-10-16 13:07:45,189 INFO  common.Storage (NNStorage.java:format(568)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2 has been successfully formatted.
2017-10-16 13:07:45,189 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:45,189 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(413)) - Saving image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 using no compression
2017-10-16 13:07:45,205 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:45,205 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(416)) - Image file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage.ckpt_0000000000000000000 of size 353 bytes saved in 0 seconds.
2017-10-16 13:07:45,473 INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2017-10-16 13:07:45,473 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:45,473 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:07:45,473 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://127.0.0.1:0
2017-10-16 13:07:45,473 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:0
2017-10-16 13:07:50,005 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:50,005 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:50,005 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56340
2017-10-16 13:07:50,005 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:50,099 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56340
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:50,099 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:50,099 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:50
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:50,099 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:50,099 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:50,099 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:50,099 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:50,099 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:50,099 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:50,099 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:50,115 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:50,115 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:50,115 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:50,115 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:50,115 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:50,115 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:50,115 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:50,115 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:50,115 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:50,115 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:50,146 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:50,146 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:07:50,146 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:07:50,146 INFO  namenode.FSImage (FSImage.java:loadFSImage(669)) - No edit log streams selected.
2017-10-16 13:07:50,146 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:50,146 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:50,146 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:50,146 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:07:50,146 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:50,146 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 1
2017-10-16 13:07:50,258 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:50,258 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 143 msecs
2017-10-16 13:07:50,259 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:0
2017-10-16 13:07:50,259 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:50,261 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56343
2017-10-16 13:07:50,262 INFO  namenode.NameNode (NameNode.java:initialize(653)) - Clients are to use lambda-pluralsight:56343 to access this namenode/service.
2017-10-16 13:07:50,263 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:50,264 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:50,264 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:50,264 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:50,264 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:50,265 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:50,265 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:50,265 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:50,270 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:50,270 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:50,270 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:50,270 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:50,270 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:50,270 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2017-10-16 13:07:50,272 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:50,272 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56343: starting
2017-10-16 13:07:50,272 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56343
2017-10-16 13:07:50,272 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:50,272 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:50,272 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1417)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/K:/HadoopDev/hadoop-2.7.3-src-buildX64-read/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2017-10-16 13:07:50,303 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - DataNode metrics system started (again)
2017-10-16 13:07:50,303 INFO  datanode.BlockScanner (BlockScanner.java:<init>(172)) - Initialized block scanner with targetBytesPerSec 1048576
2017-10-16 13:07:50,303 INFO  datanode.DataNode (DataNode.java:<init>(428)) - Configured hostname is 127.0.0.1
2017-10-16 13:07:50,303 INFO  datanode.DataNode (DataNode.java:startDataNode(1104)) - Starting DataNode with maxLockedMemory = 0
2017-10-16 13:07:50,303 INFO  datanode.DataNode (DataNode.java:initDataXceiver(902)) - Opened streaming server at /127.0.0.1:56350
2017-10-16 13:07:50,303 INFO  datanode.DataNode (DataXceiverServer.java:<init>(76)) - Balancing bandwith is 1048576 bytes/s
2017-10-16 13:07:50,303 INFO  datanode.DataNode (DataXceiverServer.java:<init>(77)) - Number threads for balancing is 5
2017-10-16 13:07:50,303 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:50,303 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.datanode is not defined
2017-10-16 13:07:50,303 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:50,303 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2017-10-16 13:07:50,303 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:50,303 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:50,303 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56351
2017-10-16 13:07:50,303 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:50,350 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:56351
2017-10-16 13:07:50,366 INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(186)) - Listening HTTP traffic on /127.0.0.1:56418
2017-10-16 13:07:50,366 INFO  datanode.DataNode (DataNode.java:startDataNode(1121)) - dnUserName = Zhibin
2017-10-16 13:07:50,366 INFO  datanode.DataNode (DataNode.java:startDataNode(1122)) - supergroup = supergroup
2017-10-16 13:07:50,366 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:50,366 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56419
2017-10-16 13:07:50,366 INFO  datanode.DataNode (DataNode.java:initIpcServer(818)) - Opened IPC server at /127.0.0.1:56419
2017-10-16 13:07:50,366 INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(152)) - Refresh request received for nameservices: null
2017-10-16 13:07:50,366 INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(197)) - Starting BPOfferServices for nameservices: <default>
2017-10-16 13:07:50,366 INFO  datanode.DataNode (BPServiceActor.java:run(795)) - Block pool <registering> (Datanode Uuid unassigned) service to lambda-pluralsight/127.0.0.1:56343 starting to offer service
2017-10-16 13:07:50,366 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56419: starting
2017-10-16 13:07:50,366 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:50,382 INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(362)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2017-10-16 13:07:50,382 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:50,382 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:50,397 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:50,397 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1 is not formatted for namespace 1669811134. Formatting...
2017-10-16 13:07:50,397 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-a30313db-b279-401b-83f5-2f491d0d3e4f for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1
2017-10-16 13:07:50,475 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:50,475 INFO  common.Storage (DataStorage.java:loadStorageDirectory(287)) - Storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2 is not formatted for namespace 1669811134. Formatting...
2017-10-16 13:07:50,475 INFO  common.Storage (DataStorage.java:createStorageID(165)) - Generated new storageID DS-f4c0035a-da3a-48cd-b266-950b4005ce32 for directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2
2017-10-16 13:07:50,491 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:50,491 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:50,522 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,522 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,522 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-1201993247-192.168.232.1-1508173665033 is not formatted for BP-1201993247-192.168.232.1-1508173665033. Formatting ...
2017-10-16 13:07:50,522 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1201993247-192.168.232.1-1508173665033 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current\BP-1201993247-192.168.232.1-1508173665033\current
2017-10-16 13:07:50,585 INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(249)) - Analyzing storage directories for bpid BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,585 INFO  common.Storage (Storage.java:lock(676)) - Locking is disabled for K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,585 INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(164)) - Block pool storage directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-1201993247-192.168.232.1-1508173665033 is not formatted for BP-1201993247-192.168.232.1-1508173665033. Formatting ...
2017-10-16 13:07:50,585 INFO  common.Storage (BlockPoolSliceStorage.java:format(277)) - Formatting block pool BP-1201993247-192.168.232.1-1508173665033 directory K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current\BP-1201993247-192.168.232.1-1508173665033\current
2017-10-16 13:07:50,600 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:50,600 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:50,632 INFO  datanode.DataNode (DataNode.java:initStorage(1365)) - Setting up storage: nsid=1669811134;bpid=BP-1201993247-192.168.232.1-1508173665033;lv=-56;nsInfo=lv=-63;cid=testClusterID;nsid=1669811134;c=0;bpid=BP-1201993247-192.168.232.1-1508173665033;dnuuid=null
2017-10-16 13:07:50,679 INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1197)) - Generated and persisted new Datanode UUID 3aa35da3-1f30-4f0e-b622-20d90ce3acdd
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-a30313db-b279-401b-83f5-2f491d0d3e4f
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current, StorageType: DISK
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(303)) - Added new volume: DS-f4c0035a-da3a-48cd-b266-950b4005ce32
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(381)) - Added volume - K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current, StorageType: DISK
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2055)) - Registered FSDatasetState MBean
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2505)) - Adding block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current...
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(402)) - Scanning block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current...
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1201993247-192.168.232.1-1508173665033 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current: 2ms
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(407)) - Time taken to scan block pool BP-1201993247-192.168.232.1-1508173665033 on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current: 2ms
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(433)) - Total time to scan all replicas for block pool BP-1201993247-192.168.232.1-1508173665033: 3ms
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current...
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(189)) - Adding replicas to map for block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current...
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1\current: 1ms
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:run(194)) - Time to add replicas to map for block pool BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2\current: 1ms
2017-10-16 13:07:50,694 INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(220)) - Total time to add all replicas to map: 1ms
2017-10-16 13:07:50,694 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1
2017-10-16 13:07:50,694 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(378)) - Now scanning bpid BP-1201993247-192.168.232.1-1508173665033 on volume K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2
2017-10-16 13:07:50,694 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-a30313db-b279-401b-83f5-2f491d0d3e4f): finished scanning block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,694 INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(332)) - Periodic Directory Tree Verification scan starting at 1508190140694 with interval 21600000
2017-10-16 13:07:50,710 INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(533)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-f4c0035a-da3a-48cd-b266-950b4005ce32): finished scanning block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,710 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56343 beginning handshake with NN
2017-10-16 13:07:50,710 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2354)) - dnInfo.length != numDataNodes
2017-10-16 13:07:50,710 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2281)) - Waiting for cluster to become active
2017-10-16 13:07:50,710 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0) storage 3aa35da3-1f30-4f0e-b622-20d90ce3acdd
2017-10-16 13:07:50,710 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:50,710 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:56350
2017-10-16 13:07:50,710 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-a30313db-b279-401b-83f5-2f491d0d3e4f): no suitable block pools found to scan.  Waiting 1814399984 ms.
2017-10-16 13:07:50,710 INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(395)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-f4c0035a-da3a-48cd-b266-950b4005ce32): no suitable block pools found to scan.  Waiting 1814399984 ms.
2017-10-16 13:07:50,710 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid null) service to lambda-pluralsight/127.0.0.1:56343 successfully registered with NN
2017-10-16 13:07:50,710 INFO  datanode.DataNode (BPServiceActor.java:offerService(626)) - For namenode lambda-pluralsight/127.0.0.1:56343 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2017-10-16 13:07:50,710 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:50,710 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-a30313db-b279-401b-83f5-2f491d0d3e4f for DN 127.0.0.1:56350
2017-10-16 13:07:50,710 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-f4c0035a-da3a-48cd-b266-950b4005ce32 for DN 127.0.0.1:56350
2017-10-16 13:07:50,710 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(511)) - Namenode Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343 trying to claim ACTIVE state with txid=1
2017-10-16 13:07:50,710 INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(523)) - Acknowledging ACTIVE Namenode Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343
2017-10-16 13:07:50,710 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-a30313db-b279-401b-83f5-2f491d0d3e4f node DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0), blocks: 0, hasStaleStorage: true, processing time: 0 msecs
2017-10-16 13:07:50,725 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-f4c0035a-da3a-48cd-b266-950b4005ce32 node DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:07:50,725 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa35690b41903d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:07:50,725 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:50,811 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:50,812 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:50,812 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownNameNode(1770)) - Shutting down the namenode
2017-10-16 13:07:50,812 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:50,812 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 1
2017-10-16 13:07:50,813 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:50,813 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:50,813 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 1 
2017-10-16 13:07:50,813 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:50,814 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000001 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:50,814 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:50,814 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56343
2017-10-16 13:07:50,815 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56343
2017-10-16 13:07:50,815 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:50,815 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:50,819 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:50,820 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:50,822 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:0
2017-10-16 13:07:50,931 INFO  namenode.NameNode (NameNode.java:createNameNode(1418)) - createNameNode []
2017-10-16 13:07:50,931 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(159)) - NameNode metrics system started (again)
2017-10-16 13:07:50,931 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(398)) - fs.defaultFS is hdfs://lambda-pluralsight:56343
2017-10-16 13:07:50,931 INFO  namenode.NameNode (NameNode.java:setClientNamenodeAddress(418)) - Clients are to use lambda-pluralsight:56343 to access this namenode/service.
2017-10-16 13:07:50,931 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1710)) - Starting Web-server for hdfs at: http://lambda-pluralsight:56340
2017-10-16 13:07:53,726 WARN  datanode.DataNode (BPServiceActor.java:offerService(725)) - IOException in offerService
java.io.EOFException: End of File Exception between local host is: "zbhuang_home/192.168.232.1"; destination host is: "lambda-pluralsight":56343; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:792)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:765)
	at org.apache.hadoop.ipc.Client.call(Client.java:1479)
	at org.apache.hadoop.ipc.Client.call(Client.java:1412)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:229)
	at com.sun.proxy.$Proxy22.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:152)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:554)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:653)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:824)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1084)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:979)
2017-10-16 13:07:55,462 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(283)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2017-10-16 13:07:55,462 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(80)) - Http request log for http.requests.namenode is not defined
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(710)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:addFilter(685)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:addFilter(693)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(86)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(609)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2017-10-16 13:07:55,462 INFO  http.HttpServer2 (HttpServer2.java:openListeners(915)) - Jetty bound to port 56340
2017-10-16 13:07:55,462 INFO  mortbay.log (Slf4jLog.java:info(67)) - jetty-6.1.26
2017-10-16 13:07:55,525 INFO  mortbay.log (Slf4jLog.java:info(67)) - Started HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56340
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(716)) - No KeyProvider found.
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(726)) - fsLock is fair:true
2017-10-16 13:07:55,525 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(239)) - dfs.block.invalidate.limit=1000
2017-10-16 13:07:55,525 INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(245)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(71)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(76)) - The block deletion will start around 2017 Oct 16 13:07:55
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map BlocksMap
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 2.0% max memory 3.6 GB = 72.8 MB
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^23 = 8388608 entries
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(367)) - dfs.block.access.token.enable=false
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(353)) - defaultReplication         = 1
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(354)) - maxReplication             = 512
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(355)) - minReplication             = 1
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(356)) - maxReplicationStreams      = 2
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(357)) - replicationRecheckInterval = 3000
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(358)) - encryptDataTransfer        = false
2017-10-16 13:07:55,525 INFO  blockmanagement.BlockManager (BlockManager.java:<init>(359)) - maxNumBlocksToLog          = 1000
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(746)) - fsOwner             = Zhibin (auth:SIMPLE)
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(747)) - supergroup          = supergroup
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(748)) - isPermissionEnabled = true
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(759)) - HA Enabled: false
2017-10-16 13:07:55,525 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(796)) - Append Enabled: true
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map INodeMap
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 1.0% max memory 3.6 GB = 36.4 MB
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^22 = 4194304 entries
2017-10-16 13:07:55,525 INFO  namenode.FSDirectory (FSDirectory.java:<init>(235)) - ACLs enabled? false
2017-10-16 13:07:55,525 INFO  namenode.FSDirectory (FSDirectory.java:<init>(239)) - XAttrs enabled? true
2017-10-16 13:07:55,525 INFO  namenode.FSDirectory (FSDirectory.java:<init>(247)) - Maximum size of an xattr: 16384
2017-10-16 13:07:55,525 INFO  namenode.NameNode (FSDirectory.java:<init>(298)) - Caching file names occuring more than 10 times
2017-10-16 13:07:55,525 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map cachedBlocks
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.25% max memory 3.6 GB = 9.1 MB
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^20 = 1048576 entries
2017-10-16 13:07:55,540 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5170)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2017-10-16 13:07:55,540 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5171)) - dfs.namenode.safemode.min.datanodes = 0
2017-10-16 13:07:55,540 INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(5172)) - dfs.namenode.safemode.extension     = 0
2017-10-16 13:07:55,540 INFO  metrics.TopMetrics (TopMetrics.java:logConf(65)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2017-10-16 13:07:55,540 INFO  metrics.TopMetrics (TopMetrics.java:logConf(67)) - NNTop conf: dfs.namenode.top.num.users = 10
2017-10-16 13:07:55,540 INFO  metrics.TopMetrics (TopMetrics.java:logConf(69)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2017-10-16 13:07:55,540 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(905)) - Retry cache on namenode is enabled
2017-10-16 13:07:55,540 INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(913)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(354)) - Computing capacity for map NameNodeRetryCache
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(355)) - VM type       = 64-bit
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(356)) - 0.029999999329447746% max memory 3.6 GB = 1.1 MB
2017-10-16 13:07:55,540 INFO  util.GSet (LightWeightGSet.java:computeCapacity(361)) - capacity      = 2^17 = 131072 entries
2017-10-16 13:07:55,540 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:55,540 INFO  common.Storage (Storage.java:tryLock(716)) - Lock on K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\in_use.lock acquired by nodename 35264@zbhuang_home
2017-10-16 13:07:55,540 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current
2017-10-16 13:07:55,540 INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(362)) - Recovering unfinalized segments in K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current
2017-10-16 13:07:55,540 INFO  namenode.FSImage (FSImage.java:loadFSImageFile(736)) - Planning to load image: FSImageFile(file=K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2017-10-16 13:07:55,540 INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(255)) - Loading 1 INodes.
2017-10-16 13:07:55,540 INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(184)) - Loaded FSImage in 0 seconds.
2017-10-16 13:07:55,540 INFO  namenode.FSImage (FSImage.java:loadFSImage(976)) - Loaded image for txid 0 from K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\fsimage_0000000000000000000
2017-10-16 13:07:55,540 INFO  namenode.FSImage (FSImage.java:loadEdits(840)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@48a44c40 expecting start txid #1
2017-10-16 13:07:55,540 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(142)) - Start loading edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002, K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002
2017-10-16 13:07:55,556 INFO  namenode.EditLogInputStream (RedundantEditLogInputStream.java:nextOp(176)) - Fast-forwarding stream 'K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002' to transaction ID 1
2017-10-16 13:07:55,556 INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(145)) - Edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000001-0000000000000000002, K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000001-0000000000000000002 of size 42 edits # 2 loaded in 0 seconds
2017-10-16 13:07:55,556 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(982)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2017-10-16 13:07:55,556 INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1218)) - Starting log segment at 3
2017-10-16 13:07:55,651 INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2017-10-16 13:07:55,651 INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(688)) - Finished loading FSImage in 110 msecs
2017-10-16 13:07:55,651 INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(343)) - RPC server is binding to lambda-pluralsight:56343
2017-10-16 13:07:55,651 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(54)) - Using callQueue class java.util.concurrent.LinkedBlockingQueue
2017-10-16 13:07:55,651 INFO  ipc.Server (Server.java:run(606)) - Starting Socket Reader #1 for port 56343
2017-10-16 13:07:55,651 INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(6035)) - Registered FSNamesystemState MBean
2017-10-16 13:07:55,651 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:55,651 INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(136)) - Number of blocks under construction: 0
2017-10-16 13:07:55,651 INFO  namenode.FSNamesystem (FSNamesystem.java:initializeReplQueues(1182)) - initializing replication queues
2017-10-16 13:07:55,651 INFO  hdfs.StateChange (FSNamesystem.java:leave(5245)) - STATE* Leaving safe mode after 0 secs
2017-10-16 13:07:55,651 INFO  hdfs.StateChange (FSNamesystem.java:leave(5257)) - STATE* Network topology has 0 racks and 0 datanodes
2017-10-16 13:07:55,651 INFO  hdfs.StateChange (FSNamesystem.java:leave(5260)) - STATE* UnderReplicatedBlocks has 0 blocks
2017-10-16 13:07:55,651 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:55,667 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2787)) - Total number of blocks            = 0
2017-10-16 13:07:55,667 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2788)) - Number of invalid blocks          = 0
2017-10-16 13:07:55,667 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2789)) - Number of under-replicated blocks = 0
2017-10-16 13:07:55,667 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2790)) - Number of  over-replicated blocks = 0
2017-10-16 13:07:55,667 INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(2792)) - Number of blocks being written    = 0
2017-10-16 13:07:55,667 INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(2794)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2017-10-16 13:07:55,667 INFO  ipc.Server (Server.java:run(836)) - IPC Server Responder: starting
2017-10-16 13:07:55,667 INFO  ipc.Server (Server.java:run(676)) - IPC Server listener on 56343: starting
2017-10-16 13:07:55,667 INFO  namenode.NameNode (NameNode.java:startCommonServices(696)) - NameNode RPC up at: lambda-pluralsight/127.0.0.1:56343
2017-10-16 13:07:55,667 INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1103)) - Starting services required for active state
2017-10-16 13:07:55,667 WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1200)) - Waiting for the Mini HDFS Cluster to start...
2017-10-16 13:07:55,667 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2017-10-16 13:07:56,668 WARN  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitClusterUp(1200)) - Waiting for the Mini HDFS Cluster to start...
2017-10-16 13:07:56,733 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActor(607)) - DatanodeCommand action : DNA_REGISTER from lambda-pluralsight/127.0.0.1:56343 with active state
2017-10-16 13:07:56,733 INFO  datanode.DataNode (BPServiceActor.java:register(749)) - Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343 beginning handshake with NN
2017-10-16 13:07:56,749 INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(889)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0) storage 3aa35da3-1f30-4f0e-b622-20d90ce3acdd
2017-10-16 13:07:56,749 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:56,749 INFO  net.NetworkTopology (NetworkTopology.java:add(426)) - Adding a new node: /default-rack/127.0.0.1:56350
2017-10-16 13:07:56,749 INFO  datanode.DataNode (BPServiceActor.java:register(768)) - Block pool Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343 successfully registered with NN
2017-10-16 13:07:56,749 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateHeartbeatState(451)) - Number of failed storage changes from 0 to 0
2017-10-16 13:07:56,749 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-a30313db-b279-401b-83f5-2f491d0d3e4f for DN 127.0.0.1:56350
2017-10-16 13:07:56,749 INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(868)) - Adding new storage ID DS-f4c0035a-da3a-48cd-b266-950b4005ce32 for DN 127.0.0.1:56350
2017-10-16 13:07:56,749 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-a30313db-b279-401b-83f5-2f491d0d3e4f node DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0), blocks: 0, hasStaleStorage: true, processing time: 0 msecs
2017-10-16 13:07:56,749 INFO  BlockStateChange (BlockManager.java:processReport(1883)) - BLOCK* processReport: from storage DS-f4c0035a-da3a-48cd-b266-950b4005ce32 node DatanodeRegistration(127.0.0.1:56350, datanodeUuid=3aa35da3-1f30-4f0e-b622-20d90ce3acdd, infoPort=56418, infoSecurePort=0, ipcPort=56419, storageInfo=lv=-56;cid=testClusterID;nsid=1669811134;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
2017-10-16 13:07:56,749 INFO  datanode.DataNode (BPServiceActor.java:blockReport(492)) - Successfully sent block report 0xa356a734dd604,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2017-10-16 13:07:56,749 INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(694)) - Got finalize command for block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:57,672 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:restartNameNode(1833)) - Restarted the namenode
2017-10-16 13:07:57,672 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2337)) - Cluster is active
2017-10-16 13:07:57,722 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1716)) - Shutting down the Mini HDFS Cluster
2017-10-16 13:07:57,722 INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNodes(1748)) - Shutting down DataNode 0
2017-10-16 13:07:57,722 WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(378)) - DirectoryScanner: shutdown has been called
2017-10-16 13:07:57,723 INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(263)) - Closing all peers.
2017-10-16 13:07:57,723 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data1, DS-a30313db-b279-401b-83f5-2f491d0d3e4f) exiting.
2017-10-16 13:07:57,723 INFO  datanode.VolumeScanner (VolumeScanner.java:run(630)) - VolumeScanner(K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\data\data2, DS-f4c0035a-da3a-48cd-b266-950b4005ce32) exiting.
2017-10-16 13:07:57,729 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:0
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56419
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56419
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:57,831 WARN  datanode.DataNode (BPServiceActor.java:offerService(704)) - BPOfferService for Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343 interrupted
2017-10-16 13:07:57,831 WARN  datanode.DataNode (BPServiceActor.java:run(835)) - Ending block pool service for: Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd) service to lambda-pluralsight/127.0.0.1:56343
2017-10-16 13:07:57,831 INFO  datanode.DataNode (BlockPoolManager.java:remove(103)) - Removed Block pool BP-1201993247-192.168.232.1-1508173665033 (Datanode Uuid 3aa35da3-1f30-4f0e-b622-20d90ce3acdd)
2017-10-16 13:07:57,831 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2515)) - Removing block pool BP-1201993247-192.168.232.1-1508173665033
2017-10-16 13:07:57,831 INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(2986)) - LazyWriter was interrupted, exiting
2017-10-16 13:07:57,831 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(184)) - Shutting down all async disk service threads
2017-10-16 13:07:57,831 INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - All async disk service threads have been shut down
2017-10-16 13:07:57,831 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(162)) - Shutting down all async lazy persist service threads
2017-10-16 13:07:57,831 INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(169)) - All async lazy persist service threads have been shut down
2017-10-16 13:07:57,831 INFO  datanode.DataNode (DataNode.java:shutdown(1777)) - Shutdown complete.
2017-10-16 13:07:57,831 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:57,831 INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1259)) - Ending log segment 3
2017-10-16 13:07:57,831 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4698)) - NameNodeEditLogRoller was interrupted, exiting
2017-10-16 13:07:57,831 INFO  namenode.FSNamesystem (FSNamesystem.java:run(4777)) - LazyPersistFileScrubber was interrupted, exiting
2017-10-16 13:07:57,831 INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(699)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 0 1 
2017-10-16 13:07:57,831 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_inprogress_0000000000000000003 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name1\current\edits_0000000000000000003-0000000000000000004
2017-10-16 13:07:57,831 INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(133)) - Finalizing edits file K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_inprogress_0000000000000000003 -> K:\HadoopDev\hadoop-2.7.3-src-buildX64-read\hadoop-hdfs-project\hadoop-hdfs\target\test\data\dfs\name2\current\edits_0000000000000000003-0000000000000000004
2017-10-16 13:07:57,831 INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:stop(2447)) - Stopping server on 56343
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:run(708)) - Stopping IPC Server listener on 56343
2017-10-16 13:07:57,831 INFO  ipc.Server (Server.java:run(841)) - Stopping IPC Server Responder
2017-10-16 13:07:57,831 INFO  blockmanagement.BlockManager (BlockManager.java:run(3613)) - Stopping ReplicationMonitor.
2017-10-16 13:07:57,847 INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1209)) - Stopping services started for active state
2017-10-16 13:07:57,847 INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1297)) - Stopping services started for standby state
2017-10-16 13:07:57,847 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@lambda-pluralsight:56340
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0

Process finished with exit code 0
